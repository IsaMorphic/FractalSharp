//
// Generated by NVIDIA NVVM Compiler
//
// Compiler Build ID: CL-23083092
// Cuda compilation tools, release 9.1, V9.1.85
// Based on LLVM 3.4svn
//

.version 6.1
.target sm_30
.address_size 64

	// .globl	render

.visible .entry render(
	.param .u64 render_param_0,
	.param .u64 render_param_1,
	.param .u32 render_param_2,
	.param .u32 render_param_3,
	.param .u32 render_param_4,
	.param .f64 render_param_5,
	.param .f64 render_param_6,
	.param .f64 render_param_7,
	.param .u32 render_param_8
)
{
	.reg .pred 	%p<71>;
	.reg .f32 	%f<4>;
	.reg .b32 	%r<246>;
	.reg .f64 	%fd<303>;
	.reg .b64 	%rd<140>;


	ld.param.u64 	%rd22, [render_param_1];
	ld.param.u32 	%r64, [render_param_2];
	ld.param.u32 	%r65, [render_param_3];
	ld.param.u32 	%r69, [render_param_4];
	ld.param.f64 	%fd57, [render_param_5];
	ld.param.f64 	%fd58, [render_param_6];
	ld.param.f64 	%fd59, [render_param_7];
	ld.param.u32 	%r66, [render_param_8];
	mov.u32 	%r70, %ntid.x;
	mov.u32 	%r71, %ctaid.x;
	mov.u32 	%r72, %tid.x;
	mad.lo.s32 	%r73, %r70, %r71, %r72;
	mov.u32 	%r74, %ntid.y;
	mov.u32 	%r75, %ctaid.y;
	mov.u32 	%r76, %tid.y;
	mad.lo.s32 	%r77, %r74, %r75, %r76;
	cvt.rn.f64.s32	%fd60, %r69;
	cvt.rn.f64.s32	%fd61, %r65;
	div.rn.f64 	%fd62, %fd61, %fd60;
	add.f64 	%fd63, %fd62, %fd62;
	cvt.rn.f64.u32	%fd64, %r73;
	mul.f64 	%fd65, %fd62, 0dC000000000000000;
	div.rn.f64 	%fd66, %fd65, %fd59;
	div.rn.f64 	%fd67, %fd63, %fd59;
	sub.f64 	%fd68, %fd67, %fd66;
	mul.f64 	%fd69, %fd64, %fd68;
	div.rn.f64 	%fd70, %fd69, %fd61;
	add.f64 	%fd71, %fd66, %fd70;
	add.f64 	%fd1, %fd71, %fd57;
	cvt.rn.f64.u32	%fd72, %r77;
	mov.f64 	%fd293, 0d4000000000000000;
	div.rn.f64 	%fd74, %fd293, %fd59;
	mov.f64 	%fd75, 0dC000000000000000;
	div.rn.f64 	%fd76, %fd75, %fd59;
	sub.f64 	%fd77, %fd74, %fd76;
	mul.f64 	%fd78, %fd72, %fd77;
	div.rn.f64 	%fd79, %fd78, %fd60;
	add.f64 	%fd80, %fd76, %fd79;
	add.f64 	%fd2, %fd80, %fd58;
	mov.u32 	%r245, 0;
	mov.f64 	%fd285, 0d0000000000000000;
	setp.lt.s32	%p1, %r66, 1;
	@%p1 bra 	BB0_1;

	mov.f64 	%fd286, %fd285;
	mov.u32 	%r223, %r245;
	mov.f64 	%fd287, %fd285;
	mov.f64 	%fd288, %fd285;

BB0_3:
	sub.f64 	%fd81, %fd286, %fd285;
	add.f64 	%fd7, %fd1, %fd81;
	add.f64 	%fd82, %fd288, %fd288;
	fma.rn.f64 	%fd287, %fd82, %fd287, %fd2;
	mul.f64 	%fd286, %fd7, %fd7;
	mul.f64 	%fd285, %fd287, %fd287;
	add.f64 	%fd289, %fd286, %fd285;
	add.s32 	%r223, %r223, 1;
	setp.lt.s32	%p2, %r223, %r66;
	setp.le.f64	%p3, %fd289, 0d4010000000000000;
	and.pred  	%p4, %p3, %p2;
	mov.f64 	%fd288, %fd7;
	@%p4 bra 	BB0_3;
	bra.uni 	BB0_4;

BB0_1:
	mov.f64 	%fd289, %fd285;
	mov.u32 	%r223, %r245;

BB0_4:
	setp.eq.s32	%p5, %r223, %r66;
	@%p5 bra 	BB0_55;

	{
	.reg .b32 %temp; 
	mov.b64 	{%r225, %temp}, %fd289;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r224}, %fd289;
	}
	mov.u32 	%r226, -1023;
	setp.gt.s32	%p6, %r224, 1048575;
	@%p6 bra 	BB0_7;

	mul.f64 	%fd289, %fd289, 0d4350000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r224}, %fd289;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%r225, %temp}, %fd289;
	}
	mov.u32 	%r226, -1077;

BB0_7:
	add.s32 	%r81, %r224, -1;
	setp.lt.u32	%p7, %r81, 2146435071;
	@%p7 bra 	BB0_9;
	bra.uni 	BB0_8;

BB0_9:
	shr.u32 	%r83, %r224, 20;
	add.s32 	%r227, %r226, %r83;
	and.b32  	%r84, %r224, -2146435073;
	or.b32  	%r85, %r84, 1072693248;
	mov.b64 	%fd291, {%r225, %r85};
	setp.lt.s32	%p9, %r85, 1073127583;
	@%p9 bra 	BB0_11;

	{
	.reg .b32 %temp; 
	mov.b64 	{%r86, %temp}, %fd291;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r87}, %fd291;
	}
	add.s32 	%r88, %r87, -1048576;
	mov.b64 	%fd291, {%r86, %r88};
	add.s32 	%r227, %r227, 1;

BB0_11:
	add.f64 	%fd85, %fd291, 0d3FF0000000000000;
	rcp.approx.ftz.f64 	%fd86, %fd85;
	neg.f64 	%fd87, %fd85;
	mov.f64 	%fd88, 0d3FF0000000000000;
	fma.rn.f64 	%fd89, %fd87, %fd86, %fd88;
	fma.rn.f64 	%fd90, %fd89, %fd89, %fd89;
	fma.rn.f64 	%fd91, %fd90, %fd86, %fd86;
	add.f64 	%fd92, %fd291, 0dBFF0000000000000;
	mul.f64 	%fd93, %fd92, %fd91;
	fma.rn.f64 	%fd94, %fd92, %fd91, %fd93;
	mul.f64 	%fd95, %fd94, %fd94;
	mov.f64 	%fd96, 0d3ED0EE258B7A8B04;
	mov.f64 	%fd97, 0d3EB1380B3AE80F1E;
	fma.rn.f64 	%fd98, %fd97, %fd95, %fd96;
	mov.f64 	%fd99, 0d3EF3B2669F02676F;
	fma.rn.f64 	%fd100, %fd98, %fd95, %fd99;
	mov.f64 	%fd101, 0d3F1745CBA9AB0956;
	fma.rn.f64 	%fd102, %fd100, %fd95, %fd101;
	mov.f64 	%fd103, 0d3F3C71C72D1B5154;
	fma.rn.f64 	%fd104, %fd102, %fd95, %fd103;
	mov.f64 	%fd105, 0d3F624924923BE72D;
	fma.rn.f64 	%fd106, %fd104, %fd95, %fd105;
	mov.f64 	%fd107, 0d3F8999999999A3C4;
	fma.rn.f64 	%fd108, %fd106, %fd95, %fd107;
	mov.f64 	%fd109, 0d3FB5555555555554;
	fma.rn.f64 	%fd110, %fd108, %fd95, %fd109;
	sub.f64 	%fd111, %fd92, %fd94;
	add.f64 	%fd112, %fd111, %fd111;
	neg.f64 	%fd113, %fd94;
	fma.rn.f64 	%fd114, %fd113, %fd92, %fd112;
	mul.f64 	%fd115, %fd91, %fd114;
	mul.f64 	%fd116, %fd95, %fd110;
	fma.rn.f64 	%fd117, %fd116, %fd94, %fd115;
	xor.b32  	%r89, %r227, -2147483648;
	mov.u32 	%r90, 1127219200;
	mov.b64 	%fd118, {%r89, %r90};
	mov.u32 	%r91, -2147483648;
	mov.b64 	%fd119, {%r91, %r90};
	sub.f64 	%fd120, %fd118, %fd119;
	mov.f64 	%fd121, 0d3FE62E42FEFA39EF;
	fma.rn.f64 	%fd122, %fd120, %fd121, %fd94;
	neg.f64 	%fd123, %fd120;
	fma.rn.f64 	%fd124, %fd123, %fd121, %fd122;
	sub.f64 	%fd125, %fd124, %fd94;
	sub.f64 	%fd126, %fd117, %fd125;
	mov.f64 	%fd127, 0d3C7ABC9E3B39803F;
	fma.rn.f64 	%fd128, %fd120, %fd127, %fd126;
	add.f64 	%fd292, %fd122, %fd128;
	bra.uni 	BB0_12;

BB0_8:
	mov.f64 	%fd83, 0d7FF0000000000000;
	fma.rn.f64 	%fd84, %fd289, %fd83, %fd83;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r82}, %fd289;
	}
	mov.b32 	 %f1, %r82;
	setp.eq.f32	%p8, %f1, 0f00000000;
	selp.f64	%fd292, 0dFFF0000000000000, %fd84, %p8;

BB0_12:
	mul.f64 	%fd130, %fd292, 0d3C7777D0FFDA0D24;
	mov.f64 	%fd131, 0d3FF71547652B82FE;
	fma.rn.f64 	%fd21, %fd292, %fd131, %fd130;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r229, %temp}, %fd293;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r228}, %fd293;
	}
	mov.u32 	%r230, -1023;
	setp.gt.s32	%p10, %r228, 1048575;
	@%p10 bra 	BB0_14;

	mov.f64 	%fd293, 0d4360000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r228}, %fd293;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%r229, %temp}, %fd293;
	}
	mov.u32 	%r230, -1077;

BB0_14:
	add.s32 	%r94, %r228, -1;
	setp.lt.u32	%p11, %r94, 2146435071;
	@%p11 bra 	BB0_16;
	bra.uni 	BB0_15;

BB0_16:
	shr.u32 	%r96, %r228, 20;
	add.s32 	%r231, %r230, %r96;
	and.b32  	%r97, %r228, -2146435073;
	or.b32  	%r98, %r97, 1072693248;
	mov.b64 	%fd294, {%r229, %r98};
	setp.lt.s32	%p13, %r98, 1073127583;
	@%p13 bra 	BB0_18;

	{
	.reg .b32 %temp; 
	mov.b64 	{%r99, %temp}, %fd294;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r100}, %fd294;
	}
	add.s32 	%r101, %r100, -1048576;
	mov.b64 	%fd294, {%r99, %r101};
	add.s32 	%r231, %r231, 1;

BB0_18:
	add.f64 	%fd135, %fd294, 0d3FF0000000000000;
	rcp.approx.ftz.f64 	%fd136, %fd135;
	neg.f64 	%fd137, %fd135;
	mov.f64 	%fd138, 0d3FF0000000000000;
	fma.rn.f64 	%fd139, %fd137, %fd136, %fd138;
	fma.rn.f64 	%fd140, %fd139, %fd139, %fd139;
	fma.rn.f64 	%fd141, %fd140, %fd136, %fd136;
	add.f64 	%fd142, %fd294, 0dBFF0000000000000;
	mul.f64 	%fd143, %fd142, %fd141;
	fma.rn.f64 	%fd144, %fd142, %fd141, %fd143;
	mul.f64 	%fd145, %fd144, %fd144;
	mov.f64 	%fd146, 0d3ED0EE258B7A8B04;
	mov.f64 	%fd147, 0d3EB1380B3AE80F1E;
	fma.rn.f64 	%fd148, %fd147, %fd145, %fd146;
	mov.f64 	%fd149, 0d3EF3B2669F02676F;
	fma.rn.f64 	%fd150, %fd148, %fd145, %fd149;
	mov.f64 	%fd151, 0d3F1745CBA9AB0956;
	fma.rn.f64 	%fd152, %fd150, %fd145, %fd151;
	mov.f64 	%fd153, 0d3F3C71C72D1B5154;
	fma.rn.f64 	%fd154, %fd152, %fd145, %fd153;
	mov.f64 	%fd155, 0d3F624924923BE72D;
	fma.rn.f64 	%fd156, %fd154, %fd145, %fd155;
	mov.f64 	%fd157, 0d3F8999999999A3C4;
	fma.rn.f64 	%fd158, %fd156, %fd145, %fd157;
	mov.f64 	%fd159, 0d3FB5555555555554;
	fma.rn.f64 	%fd160, %fd158, %fd145, %fd159;
	sub.f64 	%fd161, %fd142, %fd144;
	add.f64 	%fd162, %fd161, %fd161;
	neg.f64 	%fd163, %fd144;
	fma.rn.f64 	%fd164, %fd163, %fd142, %fd162;
	mul.f64 	%fd165, %fd141, %fd164;
	mul.f64 	%fd166, %fd145, %fd160;
	fma.rn.f64 	%fd167, %fd166, %fd144, %fd165;
	xor.b32  	%r102, %r231, -2147483648;
	mov.u32 	%r103, 1127219200;
	mov.b64 	%fd168, {%r102, %r103};
	mov.u32 	%r104, -2147483648;
	mov.b64 	%fd169, {%r104, %r103};
	sub.f64 	%fd170, %fd168, %fd169;
	mov.f64 	%fd171, 0d3FE62E42FEFA39EF;
	fma.rn.f64 	%fd172, %fd170, %fd171, %fd144;
	neg.f64 	%fd173, %fd170;
	fma.rn.f64 	%fd174, %fd173, %fd171, %fd172;
	sub.f64 	%fd175, %fd174, %fd144;
	sub.f64 	%fd176, %fd167, %fd175;
	mov.f64 	%fd177, 0d3C7ABC9E3B39803F;
	fma.rn.f64 	%fd178, %fd170, %fd177, %fd176;
	add.f64 	%fd295, %fd172, %fd178;
	bra.uni 	BB0_19;

BB0_15:
	mov.f64 	%fd133, 0d7FF0000000000000;
	fma.rn.f64 	%fd134, %fd293, %fd133, %fd133;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r95}, %fd293;
	}
	mov.b32 	 %f2, %r95;
	setp.eq.f32	%p12, %f2, 0f00000000;
	selp.f64	%fd295, 0dFFF0000000000000, %fd134, %p12;

BB0_19:
	mul.f64 	%fd179, %fd295, 0d3C7777D0FFDA0D24;
	fma.rn.f64 	%fd29, %fd295, %fd131, %fd179;
	mul.f64 	%fd181, %fd21, 0d3FE0000000000000;
	div.rn.f64 	%fd296, %fd181, %fd29;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r232}, %fd296;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%r233, %temp}, %fd296;
	}
	mov.u32 	%r234, -1023;
	setp.gt.s32	%p14, %r232, 1048575;
	@%p14 bra 	BB0_21;

	mul.f64 	%fd296, %fd296, 0d4350000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r232}, %fd296;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%r233, %temp}, %fd296;
	}
	mov.u32 	%r234, -1077;

BB0_21:
	add.s32 	%r107, %r232, -1;
	setp.lt.u32	%p15, %r107, 2146435071;
	@%p15 bra 	BB0_23;
	bra.uni 	BB0_22;

BB0_23:
	shr.u32 	%r109, %r232, 20;
	add.s32 	%r235, %r234, %r109;
	and.b32  	%r110, %r232, -2146435073;
	or.b32  	%r111, %r110, 1072693248;
	mov.b64 	%fd297, {%r233, %r111};
	setp.lt.s32	%p17, %r111, 1073127583;
	@%p17 bra 	BB0_25;

	{
	.reg .b32 %temp; 
	mov.b64 	{%r112, %temp}, %fd297;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r113}, %fd297;
	}
	add.s32 	%r114, %r113, -1048576;
	mov.b64 	%fd297, {%r112, %r114};
	add.s32 	%r235, %r235, 1;

BB0_25:
	add.f64 	%fd184, %fd297, 0d3FF0000000000000;
	rcp.approx.ftz.f64 	%fd185, %fd184;
	neg.f64 	%fd186, %fd184;
	mov.f64 	%fd187, 0d3FF0000000000000;
	fma.rn.f64 	%fd188, %fd186, %fd185, %fd187;
	fma.rn.f64 	%fd189, %fd188, %fd188, %fd188;
	fma.rn.f64 	%fd190, %fd189, %fd185, %fd185;
	add.f64 	%fd191, %fd297, 0dBFF0000000000000;
	mul.f64 	%fd192, %fd191, %fd190;
	fma.rn.f64 	%fd193, %fd191, %fd190, %fd192;
	mul.f64 	%fd194, %fd193, %fd193;
	mov.f64 	%fd195, 0d3ED0EE258B7A8B04;
	mov.f64 	%fd196, 0d3EB1380B3AE80F1E;
	fma.rn.f64 	%fd197, %fd196, %fd194, %fd195;
	mov.f64 	%fd198, 0d3EF3B2669F02676F;
	fma.rn.f64 	%fd199, %fd197, %fd194, %fd198;
	mov.f64 	%fd200, 0d3F1745CBA9AB0956;
	fma.rn.f64 	%fd201, %fd199, %fd194, %fd200;
	mov.f64 	%fd202, 0d3F3C71C72D1B5154;
	fma.rn.f64 	%fd203, %fd201, %fd194, %fd202;
	mov.f64 	%fd204, 0d3F624924923BE72D;
	fma.rn.f64 	%fd205, %fd203, %fd194, %fd204;
	mov.f64 	%fd206, 0d3F8999999999A3C4;
	fma.rn.f64 	%fd207, %fd205, %fd194, %fd206;
	mov.f64 	%fd208, 0d3FB5555555555554;
	fma.rn.f64 	%fd209, %fd207, %fd194, %fd208;
	sub.f64 	%fd210, %fd191, %fd193;
	add.f64 	%fd211, %fd210, %fd210;
	neg.f64 	%fd212, %fd193;
	fma.rn.f64 	%fd213, %fd212, %fd191, %fd211;
	mul.f64 	%fd214, %fd190, %fd213;
	mul.f64 	%fd215, %fd194, %fd209;
	fma.rn.f64 	%fd216, %fd215, %fd193, %fd214;
	xor.b32  	%r115, %r235, -2147483648;
	mov.u32 	%r116, 1127219200;
	mov.b64 	%fd217, {%r115, %r116};
	mov.u32 	%r117, -2147483648;
	mov.b64 	%fd218, {%r117, %r116};
	sub.f64 	%fd219, %fd217, %fd218;
	mov.f64 	%fd220, 0d3FE62E42FEFA39EF;
	fma.rn.f64 	%fd221, %fd219, %fd220, %fd193;
	neg.f64 	%fd222, %fd219;
	fma.rn.f64 	%fd223, %fd222, %fd220, %fd221;
	sub.f64 	%fd224, %fd223, %fd193;
	sub.f64 	%fd225, %fd216, %fd224;
	mov.f64 	%fd226, 0d3C7ABC9E3B39803F;
	fma.rn.f64 	%fd227, %fd219, %fd226, %fd225;
	add.f64 	%fd298, %fd221, %fd227;
	bra.uni 	BB0_26;

BB0_22:
	mov.f64 	%fd182, 0d7FF0000000000000;
	fma.rn.f64 	%fd183, %fd296, %fd182, %fd182;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r108}, %fd296;
	}
	mov.b32 	 %f3, %r108;
	setp.eq.f32	%p16, %f3, 0f00000000;
	selp.f64	%fd298, 0dFFF0000000000000, %fd183, %p16;

BB0_26:
	cvta.to.global.u64 	%rd23, %rd22;
	mul.f64 	%fd228, %fd298, 0d3C7777D0FFDA0D24;
	fma.rn.f64 	%fd230, %fd298, %fd131, %fd228;
	div.rn.f64 	%fd231, %fd230, %fd29;
	cvt.rn.f64.s32	%fd232, %r223;
	add.f64 	%fd233, %fd232, 0d3FF0000000000000;
	sub.f64 	%fd39, %fd233, %fd231;
	cvt.rzi.s32.f64	%r118, %fd39;
	add.s32 	%r119, %r64, -1;
	rem.s32 	%r120, %r118, %r119;
	mul.wide.s32 	%rd24, %r120, 4;
	add.s64 	%rd25, %rd23, %rd24;
	ld.global.u32 	%r34, [%rd25];
	add.f64 	%fd302, %fd39, 0d3FF0000000000000;
	cvt.rzi.s32.f64	%r121, %fd302;
	rem.s32 	%r122, %r121, %r119;
	mul.wide.s32 	%rd26, %r122, 4;
	add.s64 	%rd27, %rd23, %rd26;
	ld.global.u32 	%r35, [%rd27];
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r36}, %fd39;
	}
	and.b32  	%r123, %r36, 2147483647;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r124, %temp}, %fd39;
	}
	mov.f64 	%fd234, 0d3FF0000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r125}, %fd234;
	}
	and.b32  	%r126, %r125, 2147483647;
	mov.b64 	%fd299, {%r124, %r123};
	{
	.reg .b32 %temp; 
	mov.b64 	{%r127, %temp}, %fd234;
	}
	mov.b64 	%fd300, {%r127, %r126};
	setp.gt.u32	%p18, %r123, 2146435071;
	setp.gt.u32	%p19, %r126, 2146435071;
	or.pred  	%p20, %p18, %p19;
	@%p20 bra 	BB0_52;
	bra.uni 	BB0_27;

BB0_52:
	setp.gtu.f64	%p67, %fd299, 0d7FF0000000000000;
	setp.gtu.f64	%p68, %fd300, 0d7FF0000000000000;
	or.pred  	%p69, %p67, %p68;
	@%p69 bra 	BB0_54;

	setp.eq.f64	%p70, %fd299, 0d7FF0000000000000;
	selp.f64	%fd302, 0dFFF8000000000000, %fd39, %p70;
	bra.uni 	BB0_54;

BB0_27:
	setp.eq.f64	%p21, %fd300, 0d0000000000000000;
	mov.f64 	%fd302, 0dFFF8000000000000;
	@%p21 bra 	BB0_54;

	setp.ltu.f64	%p22, %fd299, %fd300;
	mov.f64 	%fd302, %fd39;
	@%p22 bra 	BB0_54;

	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r128}, %fd299;
	}
	shr.u32 	%r236, %r128, 20;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r129}, %fd300;
	}
	shr.u32 	%r237, %r129, 20;
	setp.ne.s32	%p23, %r236, 0;
	@%p23 bra 	BB0_31;

	mul.f64 	%fd299, %fd299, 0d4350000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r130}, %fd299;
	}
	shr.u32 	%r131, %r130, 20;
	add.s32 	%r236, %r131, -54;

BB0_31:
	setp.ne.s32	%p24, %r237, 0;
	@%p24 bra 	BB0_33;

	mul.f64 	%fd300, %fd300, 0d4350000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r132}, %fd300;
	}
	shr.u32 	%r133, %r132, 20;
	add.s32 	%r237, %r133, -54;

BB0_33:
	mov.b64 	 %rd29, %fd299;
	and.b64  	%rd30, %rd29, 4503599627370495;
	or.b64  	%rd8, %rd30, 4503599627370496;
	mov.b64 	 %rd31, %fd300;
	and.b64  	%rd32, %rd31, 4503599627370495;
	or.b64  	%rd2, %rd32, 4503599627370496;
	sub.s32 	%r51, %r236, %r237;
	not.b32 	%r134, %r236;
	add.s32 	%r135, %r237, %r134;
	mov.u32 	%r136, -1;
	max.s32 	%r137, %r135, %r136;
	add.s32 	%r138, %r236, 2;
	sub.s32 	%r139, %r138, %r237;
	add.s32 	%r44, %r139, %r137;
	and.b32  	%r45, %r44, 3;
	setp.eq.s32	%p25, %r45, 0;
	mov.u64 	%rd139, 0;
	@%p25 bra 	BB0_39;

	setp.eq.s32	%p26, %r45, 1;
	@%p26 bra 	BB0_38;

	setp.eq.s32	%p27, %r45, 2;
	@%p27 bra 	BB0_37;

	sub.s64 	%rd33, %rd8, %rd2;
	mov.b64 	 %fd236, %rd33;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r140}, %fd236;
	}
	setp.lt.s32	%p28, %r140, 0;
	selp.b64	%rd34, %rd8, %rd33, %p28;
	add.s64 	%rd8, %rd34, %rd34;
	add.s32 	%r51, %r51, -1;

BB0_37:
	sub.s64 	%rd35, %rd8, %rd2;
	mov.b64 	 %fd237, %rd35;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r141}, %fd237;
	}
	setp.lt.s32	%p29, %r141, 0;
	selp.b64	%rd36, %rd8, %rd35, %p29;
	add.s64 	%rd8, %rd36, %rd36;
	add.s32 	%r51, %r51, -1;

BB0_38:
	sub.s64 	%rd37, %rd8, %rd2;
	mov.b64 	 %fd238, %rd37;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r142}, %fd238;
	}
	setp.lt.s32	%p30, %r142, 0;
	selp.b64	%rd38, %rd8, %rd37, %p30;
	add.s64 	%rd8, %rd38, %rd38;
	add.s32 	%r51, %r51, -1;
	mov.u64 	%rd139, %rd8;

BB0_39:
	setp.lt.u32	%p31, %r44, 4;
	@%p31 bra 	BB0_49;

	mov.u32 	%r143, 2;
	sub.s32 	%r144, %r143, %r51;
	max.s32 	%r146, %r144, %r136;
	add.s32 	%r147, %r51, %r146;
	add.s32 	%r148, %r147, 1;
	shr.u32 	%r149, %r148, 2;
	add.s32 	%r52, %r149, 1;
	and.b32  	%r53, %r52, 3;
	setp.eq.s32	%p32, %r53, 0;
	mov.u64 	%rd139, 0;
	@%p32 bra 	BB0_46;

	setp.eq.s32	%p33, %r53, 1;
	@%p33 bra 	BB0_45;

	setp.eq.s32	%p34, %r53, 2;
	@%p34 bra 	BB0_44;

	sub.s64 	%rd40, %rd8, %rd2;
	mov.b64 	 %fd239, %rd40;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r150}, %fd239;
	}
	setp.lt.s32	%p35, %r150, 0;
	selp.b64	%rd41, %rd8, %rd40, %p35;
	add.s64 	%rd42, %rd41, %rd41;
	sub.s64 	%rd43, %rd42, %rd2;
	mov.b64 	 %fd240, %rd43;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r151}, %fd240;
	}
	setp.lt.s32	%p36, %r151, 0;
	selp.b64	%rd44, %rd42, %rd43, %p36;
	add.s64 	%rd45, %rd44, %rd44;
	sub.s64 	%rd46, %rd45, %rd2;
	mov.b64 	 %fd241, %rd46;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r152}, %fd241;
	}
	setp.lt.s32	%p37, %r152, 0;
	selp.b64	%rd47, %rd45, %rd46, %p37;
	add.s64 	%rd48, %rd47, %rd47;
	sub.s64 	%rd49, %rd48, %rd2;
	mov.b64 	 %fd242, %rd49;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r153}, %fd242;
	}
	setp.lt.s32	%p38, %r153, 0;
	selp.b64	%rd50, %rd48, %rd49, %p38;
	add.s64 	%rd8, %rd50, %rd50;
	add.s32 	%r51, %r51, -4;

BB0_44:
	sub.s64 	%rd51, %rd8, %rd2;
	mov.b64 	 %fd243, %rd51;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r154}, %fd243;
	}
	setp.lt.s32	%p39, %r154, 0;
	selp.b64	%rd52, %rd8, %rd51, %p39;
	add.s64 	%rd53, %rd52, %rd52;
	sub.s64 	%rd54, %rd53, %rd2;
	mov.b64 	 %fd244, %rd54;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r155}, %fd244;
	}
	setp.lt.s32	%p40, %r155, 0;
	selp.b64	%rd55, %rd53, %rd54, %p40;
	add.s64 	%rd56, %rd55, %rd55;
	sub.s64 	%rd57, %rd56, %rd2;
	mov.b64 	 %fd245, %rd57;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r156}, %fd245;
	}
	setp.lt.s32	%p41, %r156, 0;
	selp.b64	%rd58, %rd56, %rd57, %p41;
	add.s64 	%rd59, %rd58, %rd58;
	sub.s64 	%rd60, %rd59, %rd2;
	mov.b64 	 %fd246, %rd60;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r157}, %fd246;
	}
	setp.lt.s32	%p42, %r157, 0;
	selp.b64	%rd61, %rd59, %rd60, %p42;
	add.s64 	%rd8, %rd61, %rd61;
	add.s32 	%r51, %r51, -4;

BB0_45:
	sub.s64 	%rd62, %rd8, %rd2;
	mov.b64 	 %fd247, %rd62;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r158}, %fd247;
	}
	setp.lt.s32	%p43, %r158, 0;
	selp.b64	%rd63, %rd8, %rd62, %p43;
	add.s64 	%rd64, %rd63, %rd63;
	sub.s64 	%rd65, %rd64, %rd2;
	mov.b64 	 %fd248, %rd65;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r159}, %fd248;
	}
	setp.lt.s32	%p44, %r159, 0;
	selp.b64	%rd66, %rd64, %rd65, %p44;
	add.s64 	%rd67, %rd66, %rd66;
	sub.s64 	%rd68, %rd67, %rd2;
	mov.b64 	 %fd249, %rd68;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r160}, %fd249;
	}
	setp.lt.s32	%p45, %r160, 0;
	selp.b64	%rd69, %rd67, %rd68, %p45;
	add.s64 	%rd70, %rd69, %rd69;
	sub.s64 	%rd71, %rd70, %rd2;
	mov.b64 	 %fd250, %rd71;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r161}, %fd250;
	}
	setp.lt.s32	%p46, %r161, 0;
	selp.b64	%rd72, %rd70, %rd71, %p46;
	add.s64 	%rd8, %rd72, %rd72;
	add.s32 	%r51, %r51, -4;
	mov.u64 	%rd139, %rd8;

BB0_46:
	setp.lt.u32	%p47, %r52, 4;
	@%p47 bra 	BB0_49;

	mov.u64 	%rd139, %rd8;

BB0_48:
	sub.s64 	%rd73, %rd139, %rd2;
	mov.b64 	 %fd251, %rd73;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r162}, %fd251;
	}
	setp.lt.s32	%p48, %r162, 0;
	selp.b64	%rd74, %rd139, %rd73, %p48;
	add.s64 	%rd75, %rd74, %rd74;
	sub.s64 	%rd76, %rd75, %rd2;
	mov.b64 	 %fd252, %rd76;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r163}, %fd252;
	}
	setp.lt.s32	%p49, %r163, 0;
	selp.b64	%rd77, %rd75, %rd76, %p49;
	add.s64 	%rd78, %rd77, %rd77;
	sub.s64 	%rd79, %rd78, %rd2;
	mov.b64 	 %fd253, %rd79;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r164}, %fd253;
	}
	setp.lt.s32	%p50, %r164, 0;
	selp.b64	%rd80, %rd78, %rd79, %p50;
	add.s64 	%rd81, %rd80, %rd80;
	sub.s64 	%rd82, %rd81, %rd2;
	mov.b64 	 %fd254, %rd82;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r165}, %fd254;
	}
	setp.lt.s32	%p51, %r165, 0;
	selp.b64	%rd83, %rd81, %rd82, %p51;
	add.s64 	%rd84, %rd83, %rd83;
	sub.s64 	%rd85, %rd84, %rd2;
	mov.b64 	 %fd255, %rd85;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r166}, %fd255;
	}
	setp.lt.s32	%p52, %r166, 0;
	selp.b64	%rd86, %rd84, %rd85, %p52;
	add.s64 	%rd87, %rd86, %rd86;
	sub.s64 	%rd88, %rd87, %rd2;
	mov.b64 	 %fd256, %rd88;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r167}, %fd256;
	}
	setp.lt.s32	%p53, %r167, 0;
	selp.b64	%rd89, %rd87, %rd88, %p53;
	add.s64 	%rd90, %rd89, %rd89;
	sub.s64 	%rd91, %rd90, %rd2;
	mov.b64 	 %fd257, %rd91;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r168}, %fd257;
	}
	setp.lt.s32	%p54, %r168, 0;
	selp.b64	%rd92, %rd90, %rd91, %p54;
	add.s64 	%rd93, %rd92, %rd92;
	sub.s64 	%rd94, %rd93, %rd2;
	mov.b64 	 %fd258, %rd94;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r169}, %fd258;
	}
	setp.lt.s32	%p55, %r169, 0;
	selp.b64	%rd95, %rd93, %rd94, %p55;
	add.s64 	%rd96, %rd95, %rd95;
	sub.s64 	%rd97, %rd96, %rd2;
	mov.b64 	 %fd259, %rd97;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r170}, %fd259;
	}
	setp.lt.s32	%p56, %r170, 0;
	selp.b64	%rd98, %rd96, %rd97, %p56;
	add.s64 	%rd99, %rd98, %rd98;
	sub.s64 	%rd100, %rd99, %rd2;
	mov.b64 	 %fd260, %rd100;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r171}, %fd260;
	}
	setp.lt.s32	%p57, %r171, 0;
	selp.b64	%rd101, %rd99, %rd100, %p57;
	add.s64 	%rd102, %rd101, %rd101;
	sub.s64 	%rd103, %rd102, %rd2;
	mov.b64 	 %fd261, %rd103;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r172}, %fd261;
	}
	setp.lt.s32	%p58, %r172, 0;
	selp.b64	%rd104, %rd102, %rd103, %p58;
	add.s64 	%rd105, %rd104, %rd104;
	sub.s64 	%rd106, %rd105, %rd2;
	mov.b64 	 %fd262, %rd106;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r173}, %fd262;
	}
	setp.lt.s32	%p59, %r173, 0;
	selp.b64	%rd107, %rd105, %rd106, %p59;
	add.s64 	%rd108, %rd107, %rd107;
	sub.s64 	%rd109, %rd108, %rd2;
	mov.b64 	 %fd263, %rd109;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r174}, %fd263;
	}
	setp.lt.s32	%p60, %r174, 0;
	selp.b64	%rd110, %rd108, %rd109, %p60;
	add.s64 	%rd111, %rd110, %rd110;
	sub.s64 	%rd112, %rd111, %rd2;
	mov.b64 	 %fd264, %rd112;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r175}, %fd264;
	}
	setp.lt.s32	%p61, %r175, 0;
	selp.b64	%rd113, %rd111, %rd112, %p61;
	add.s64 	%rd114, %rd113, %rd113;
	sub.s64 	%rd115, %rd114, %rd2;
	mov.b64 	 %fd265, %rd115;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r176}, %fd265;
	}
	setp.lt.s32	%p62, %r176, 0;
	selp.b64	%rd116, %rd114, %rd115, %p62;
	add.s64 	%rd117, %rd116, %rd116;
	sub.s64 	%rd118, %rd117, %rd2;
	mov.b64 	 %fd266, %rd118;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r177}, %fd266;
	}
	setp.lt.s32	%p63, %r177, 0;
	selp.b64	%rd119, %rd117, %rd118, %p63;
	add.s64 	%rd139, %rd119, %rd119;
	add.s32 	%r61, %r51, -16;
	add.s32 	%r178, %r51, -15;
	setp.gt.s32	%p64, %r178, 0;
	mov.u32 	%r51, %r61;
	@%p64 bra 	BB0_48;

BB0_49:
	shr.u64 	%rd20, %rd139, 1;
	setp.eq.s64	%p65, %rd20, 0;
	mov.f64 	%fd301, 0d0000000000000000;
	@%p65 bra 	BB0_51;

	mov.b64 	 %fd268, %rd20;
	mul.f64 	%fd269, %fd268, 0d4350000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r179}, %fd269;
	}
	shr.u32 	%r180, %r179, 20;
	mov.u32 	%r181, 55;
	sub.s32 	%r182, %r181, %r180;
	sub.s32 	%r183, %r237, %r182;
	shl.b64 	%rd120, %rd20, %r182;
	setp.lt.s32	%p66, %r183, 1;
	mov.u32 	%r184, 1;
	sub.s32 	%r185, %r184, %r183;
	shr.u64 	%rd121, %rd120, %r185;
	add.s32 	%r186, %r183, 4095;
	cvt.u64.u32	%rd122, %r186;
	shl.b64 	%rd123, %rd122, 52;
	add.s64 	%rd124, %rd123, %rd120;
	selp.b64	%rd125, %rd121, %rd124, %p66;
	mov.b64 	 %fd301, %rd125;

BB0_51:
	and.b32  	%r187, %r36, -2147483648;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r188}, %fd301;
	}
	or.b32  	%r189, %r188, %r187;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r190, %temp}, %fd301;
	}
	mov.b64 	%fd302, {%r190, %r189};

BB0_54:
	mov.f64 	%fd284, 0d3FF0000000000000;
	bfe.u32 	%r191, %r34, 16, 8;
	bfe.u32 	%r192, %r34, 8, 8;
	bfe.u32 	%r193, %r35, 16, 8;
	bfe.u32 	%r194, %r35, 8, 8;
	cvt.rn.f64.s32	%fd270, %r191;
	sub.f64 	%fd272, %fd284, %fd302;
	mul.f64 	%fd273, %fd270, %fd272;
	cvt.rn.f64.s32	%fd274, %r193;
	fma.rn.f64 	%fd275, %fd274, %fd302, %fd273;
	cvt.rzi.s32.f64	%r195, %fd275;
	cvt.rn.f64.s32	%fd276, %r192;
	mul.f64 	%fd277, %fd276, %fd272;
	cvt.rn.f64.s32	%fd278, %r194;
	fma.rn.f64 	%fd279, %fd278, %fd302, %fd277;
	cvt.rzi.s32.f64	%r196, %fd279;
	and.b32  	%r197, %r34, 255;
	cvt.rn.f64.s32	%fd280, %r197;
	mul.f64 	%fd281, %fd280, %fd272;
	and.b32  	%r198, %r35, 255;
	cvt.rn.f64.s32	%fd282, %r198;
	fma.rn.f64 	%fd283, %fd282, %fd302, %fd281;
	cvt.rzi.s32.f64	%r199, %fd283;
	shl.b32 	%r200, %r195, 16;
	shl.b32 	%r201, %r196, 8;
	add.s32 	%r202, %r200, %r201;
	add.s32 	%r203, %r202, %r199;
	add.s32 	%r245, %r203, -16777216;

BB0_55:
	ld.param.u64 	%rd129, [render_param_0];
	mov.u32 	%r221, %tid.x;
	mov.u32 	%r220, %ctaid.x;
	mov.u32 	%r219, %ntid.x;
	mad.lo.s32 	%r218, %r219, %r220, %r221;
	ld.param.u32 	%r217, [render_param_3];
	mov.u32 	%r216, %tid.y;
	mov.u32 	%r215, %ctaid.y;
	mov.u32 	%r214, %ntid.y;
	mad.lo.s32 	%r213, %r214, %r215, %r216;
	mad.lo.s32 	%r212, %r213, %r217, %r218;
	cvta.to.global.u64 	%rd126, %rd129;
	mul.wide.s32 	%rd127, %r212, 4;
	add.s64 	%rd128, %rd126, %rd127;
	st.global.u32 	[%rd128], %r245;
	ret;
}


