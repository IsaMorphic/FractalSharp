//
// Generated by NVIDIA NVVM Compiler
//
// Compiler Build ID: CL-23083092
// Cuda compilation tools, release 9.1, V9.1.85
// Based on LLVM 3.4svn
//

.version 6.1
.target sm_30
.address_size 64

	// .globl	perturbation

.visible .entry perturbation(
	.param .u64 perturbation_param_0,
	.param .u64 perturbation_param_1,
	.param .u32 perturbation_param_2,
	.param .u64 perturbation_param_3,
	.param .u32 perturbation_param_4,
	.param .u32 perturbation_param_5,
	.param .u32 perturbation_param_6,
	.param .u32 perturbation_param_7,
	.param .u32 perturbation_param_8,
	.param .u32 perturbation_param_9,
	.param .u32 perturbation_param_10,
	.param .f64 perturbation_param_11,
	.param .f64 perturbation_param_12,
	.param .u32 perturbation_param_13,
	.param .u32 perturbation_param_14
)
{
	.reg .pred 	%p<95>;
	.reg .f32 	%f<4>;
	.reg .b32 	%r<307>;
	.reg .f64 	%fd<303>;
	.reg .b64 	%rd<161>;


	ld.param.u64 	%rd23, [perturbation_param_0];
	ld.param.u64 	%rd24, [perturbation_param_1];
	ld.param.u32 	%r90, [perturbation_param_2];
	ld.param.u64 	%rd25, [perturbation_param_3];
	ld.param.u32 	%r91, [perturbation_param_4];
	ld.param.u32 	%r92, [perturbation_param_5];
	ld.param.u32 	%r93, [perturbation_param_6];
	ld.param.u32 	%r94, [perturbation_param_7];
	ld.param.u32 	%r95, [perturbation_param_8];
	ld.param.u32 	%r96, [perturbation_param_9];
	ld.param.u32 	%r97, [perturbation_param_10];
	ld.param.f64 	%fd53, [perturbation_param_11];
	ld.param.f64 	%fd54, [perturbation_param_12];
	ld.param.u32 	%r98, [perturbation_param_13];
	ld.param.u32 	%r99, [perturbation_param_14];
	cvta.to.global.u64 	%rd1, %rd25;
	mov.u32 	%r100, %ntid.x;
	mov.u32 	%r101, %ctaid.x;
	mul.lo.s32 	%r102, %r94, %r92;
	mad.lo.s32 	%r103, %r100, %r101, %r102;
	mov.u32 	%r104, %tid.x;
	add.s32 	%r1, %r103, %r104;
	mov.u32 	%r105, %ntid.y;
	mov.u32 	%r106, %ctaid.y;
	mul.lo.s32 	%r107, %r95, %r93;
	mad.lo.s32 	%r108, %r105, %r106, %r107;
	mov.u32 	%r109, %tid.y;
	add.s32 	%r302, %r108, %r109;
	rem.u32 	%r110, %r1, %r98;
	setp.ne.s32	%p3, %r110, 0;
	@%p3 bra 	BB0_83;

	rem.u32 	%r111, %r302, %r98;
	setp.ne.s32	%p4, %r111, 0;
	@%p4 bra 	BB0_83;

	div.u32 	%r112, %r1, %r98;
	mov.pred 	%p94, 0;
	and.b32  	%r113, %r112, 1;
	setp.eq.b32	%p6, %r113, 1;
	@%p6 bra 	BB0_4;

	div.u32 	%r114, %r302, %r98;
	and.b32  	%r115, %r114, 1;
	setp.eq.b32	%p7, %r115, 1;
	not.pred 	%p94, %p7;

BB0_4:
	setp.ne.s32	%p8, %r98, %r99;
	and.pred  	%p9, %p94, %p8;
	@%p9 bra 	BB0_83;

	cvta.to.global.u64 	%rd2, %rd24;
	mul.lo.s32 	%r117, %r96, %r94;
	cvt.rn.f64.u32	%fd55, %r117;
	add.f64 	%fd56, %fd53, %fd53;
	cvt.rn.f64.u32	%fd57, %r1;
	mul.f64 	%fd58, %fd56, %fd57;
	div.rn.f64 	%fd59, %fd58, %fd55;
	sub.f64 	%fd1, %fd59, %fd53;
	mul.lo.s32 	%r118, %r97, %r95;
	cvt.rn.f64.u32	%fd60, %r118;
	add.f64 	%fd61, %fd54, %fd54;
	cvt.rn.f64.u32	%fd62, %r302;
	mul.f64 	%fd63, %fd61, %fd62;
	div.rn.f64 	%fd64, %fd63, %fd60;
	sub.f64 	%fd2, %fd64, %fd54;
	ld.global.v2.f64 	{%fd286, %fd287}, [%rd1];
	mov.u32 	%r279, 0;
	mov.f64 	%fd288, %fd2;
	mov.f64 	%fd289, %fd1;

BB0_6:
	add.f64 	%fd67, %fd289, %fd286;
	add.f64 	%fd68, %fd288, %fd287;
	mul.f64 	%fd69, %fd289, %fd67;
	mul.f64 	%fd70, %fd288, %fd68;
	sub.f64 	%fd71, %fd69, %fd70;
	mul.f64 	%fd72, %fd288, %fd67;
	fma.rn.f64 	%fd73, %fd289, %fd68, %fd72;
	add.f64 	%fd289, %fd1, %fd71;
	add.f64 	%fd288, %fd2, %fd73;
	add.s32 	%r279, %r279, 1;
	mul.wide.s32 	%rd26, %r279, 16;
	add.s64 	%rd27, %rd1, %rd26;
	ld.global.v2.f64 	{%fd286, %fd287}, [%rd27];
	mul.f64 	%fd76, %fd286, 0d3FE0000000000000;
	mul.f64 	%fd77, %fd287, 0d0000000000000000;
	sub.f64 	%fd78, %fd76, %fd77;
	mul.f64 	%fd79, %fd287, 0d3FE0000000000000;
	fma.rn.f64 	%fd80, %fd286, 0d0000000000000000, %fd79;
	add.f64 	%fd81, %fd78, %fd289;
	add.f64 	%fd82, %fd80, %fd288;
	mul.f64 	%fd83, %fd82, %fd82;
	fma.rn.f64 	%fd290, %fd81, %fd81, %fd83;
	setp.lt.f64	%p10, %fd290, 0d4070000000000000;
	setp.lt.s32	%p11, %r279, %r91;
	and.pred  	%p12, %p10, %p11;
	@%p12 bra 	BB0_6;

	setp.eq.s32	%p13, %r279, %r91;
	mov.u32 	%r301, -16777216;
	@%p13 bra 	BB0_58;

	{
	.reg .b32 %temp; 
	mov.b64 	{%r281, %temp}, %fd290;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r280}, %fd290;
	}
	mov.u32 	%r282, -1023;
	setp.gt.s32	%p14, %r280, 1048575;
	@%p14 bra 	BB0_10;

	mul.f64 	%fd290, %fd290, 0d4350000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r280}, %fd290;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%r281, %temp}, %fd290;
	}
	mov.u32 	%r282, -1077;

BB0_10:
	add.s32 	%r122, %r280, -1;
	setp.lt.u32	%p15, %r122, 2146435071;
	@%p15 bra 	BB0_12;
	bra.uni 	BB0_11;

BB0_12:
	shr.u32 	%r124, %r280, 20;
	add.s32 	%r283, %r282, %r124;
	and.b32  	%r125, %r280, -2146435073;
	or.b32  	%r126, %r125, 1072693248;
	mov.b64 	%fd291, {%r281, %r126};
	setp.lt.s32	%p17, %r126, 1073127583;
	@%p17 bra 	BB0_14;

	{
	.reg .b32 %temp; 
	mov.b64 	{%r127, %temp}, %fd291;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r128}, %fd291;
	}
	add.s32 	%r129, %r128, -1048576;
	mov.b64 	%fd291, {%r127, %r129};
	add.s32 	%r283, %r283, 1;

BB0_14:
	add.f64 	%fd86, %fd291, 0d3FF0000000000000;
	rcp.approx.ftz.f64 	%fd87, %fd86;
	neg.f64 	%fd88, %fd86;
	mov.f64 	%fd89, 0d3FF0000000000000;
	fma.rn.f64 	%fd90, %fd88, %fd87, %fd89;
	fma.rn.f64 	%fd91, %fd90, %fd90, %fd90;
	fma.rn.f64 	%fd92, %fd91, %fd87, %fd87;
	add.f64 	%fd93, %fd291, 0dBFF0000000000000;
	mul.f64 	%fd94, %fd93, %fd92;
	fma.rn.f64 	%fd95, %fd93, %fd92, %fd94;
	mul.f64 	%fd96, %fd95, %fd95;
	mov.f64 	%fd97, 0d3ED0EE258B7A8B04;
	mov.f64 	%fd98, 0d3EB1380B3AE80F1E;
	fma.rn.f64 	%fd99, %fd98, %fd96, %fd97;
	mov.f64 	%fd100, 0d3EF3B2669F02676F;
	fma.rn.f64 	%fd101, %fd99, %fd96, %fd100;
	mov.f64 	%fd102, 0d3F1745CBA9AB0956;
	fma.rn.f64 	%fd103, %fd101, %fd96, %fd102;
	mov.f64 	%fd104, 0d3F3C71C72D1B5154;
	fma.rn.f64 	%fd105, %fd103, %fd96, %fd104;
	mov.f64 	%fd106, 0d3F624924923BE72D;
	fma.rn.f64 	%fd107, %fd105, %fd96, %fd106;
	mov.f64 	%fd108, 0d3F8999999999A3C4;
	fma.rn.f64 	%fd109, %fd107, %fd96, %fd108;
	mov.f64 	%fd110, 0d3FB5555555555554;
	fma.rn.f64 	%fd111, %fd109, %fd96, %fd110;
	sub.f64 	%fd112, %fd93, %fd95;
	add.f64 	%fd113, %fd112, %fd112;
	neg.f64 	%fd114, %fd95;
	fma.rn.f64 	%fd115, %fd114, %fd93, %fd113;
	mul.f64 	%fd116, %fd92, %fd115;
	mul.f64 	%fd117, %fd96, %fd111;
	fma.rn.f64 	%fd118, %fd117, %fd95, %fd116;
	xor.b32  	%r130, %r283, -2147483648;
	mov.u32 	%r131, 1127219200;
	mov.b64 	%fd119, {%r130, %r131};
	mov.u32 	%r132, -2147483648;
	mov.b64 	%fd120, {%r132, %r131};
	sub.f64 	%fd121, %fd119, %fd120;
	mov.f64 	%fd122, 0d3FE62E42FEFA39EF;
	fma.rn.f64 	%fd123, %fd121, %fd122, %fd95;
	neg.f64 	%fd124, %fd121;
	fma.rn.f64 	%fd125, %fd124, %fd122, %fd123;
	sub.f64 	%fd126, %fd125, %fd95;
	sub.f64 	%fd127, %fd118, %fd126;
	mov.f64 	%fd128, 0d3C7ABC9E3B39803F;
	fma.rn.f64 	%fd129, %fd121, %fd128, %fd127;
	add.f64 	%fd292, %fd123, %fd129;
	bra.uni 	BB0_15;

BB0_11:
	mov.f64 	%fd84, 0d7FF0000000000000;
	fma.rn.f64 	%fd85, %fd290, %fd84, %fd84;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r123}, %fd290;
	}
	mov.b32 	 %f1, %r123;
	setp.eq.f32	%p16, %f1, 0f00000000;
	selp.f64	%fd292, 0dFFF0000000000000, %fd85, %p16;

BB0_15:
	mul.f64 	%fd131, %fd292, 0d3C7777D0FFDA0D24;
	mov.f64 	%fd132, 0d3FF71547652B82FE;
	fma.rn.f64 	%fd22, %fd292, %fd132, %fd131;
	mov.f64 	%fd293, 0d4000000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r285, %temp}, %fd293;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r284}, %fd293;
	}
	mov.u32 	%r286, -1023;
	setp.gt.s32	%p18, %r284, 1048575;
	@%p18 bra 	BB0_17;

	mov.f64 	%fd293, 0d4360000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r284}, %fd293;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%r285, %temp}, %fd293;
	}
	mov.u32 	%r286, -1077;

BB0_17:
	add.s32 	%r135, %r284, -1;
	setp.lt.u32	%p19, %r135, 2146435071;
	@%p19 bra 	BB0_19;
	bra.uni 	BB0_18;

BB0_19:
	shr.u32 	%r137, %r284, 20;
	add.s32 	%r287, %r286, %r137;
	and.b32  	%r138, %r284, -2146435073;
	or.b32  	%r139, %r138, 1072693248;
	mov.b64 	%fd294, {%r285, %r139};
	setp.lt.s32	%p21, %r139, 1073127583;
	@%p21 bra 	BB0_21;

	{
	.reg .b32 %temp; 
	mov.b64 	{%r140, %temp}, %fd294;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r141}, %fd294;
	}
	add.s32 	%r142, %r141, -1048576;
	mov.b64 	%fd294, {%r140, %r142};
	add.s32 	%r287, %r287, 1;

BB0_21:
	add.f64 	%fd136, %fd294, 0d3FF0000000000000;
	rcp.approx.ftz.f64 	%fd137, %fd136;
	neg.f64 	%fd138, %fd136;
	mov.f64 	%fd139, 0d3FF0000000000000;
	fma.rn.f64 	%fd140, %fd138, %fd137, %fd139;
	fma.rn.f64 	%fd141, %fd140, %fd140, %fd140;
	fma.rn.f64 	%fd142, %fd141, %fd137, %fd137;
	add.f64 	%fd143, %fd294, 0dBFF0000000000000;
	mul.f64 	%fd144, %fd143, %fd142;
	fma.rn.f64 	%fd145, %fd143, %fd142, %fd144;
	mul.f64 	%fd146, %fd145, %fd145;
	mov.f64 	%fd147, 0d3ED0EE258B7A8B04;
	mov.f64 	%fd148, 0d3EB1380B3AE80F1E;
	fma.rn.f64 	%fd149, %fd148, %fd146, %fd147;
	mov.f64 	%fd150, 0d3EF3B2669F02676F;
	fma.rn.f64 	%fd151, %fd149, %fd146, %fd150;
	mov.f64 	%fd152, 0d3F1745CBA9AB0956;
	fma.rn.f64 	%fd153, %fd151, %fd146, %fd152;
	mov.f64 	%fd154, 0d3F3C71C72D1B5154;
	fma.rn.f64 	%fd155, %fd153, %fd146, %fd154;
	mov.f64 	%fd156, 0d3F624924923BE72D;
	fma.rn.f64 	%fd157, %fd155, %fd146, %fd156;
	mov.f64 	%fd158, 0d3F8999999999A3C4;
	fma.rn.f64 	%fd159, %fd157, %fd146, %fd158;
	mov.f64 	%fd160, 0d3FB5555555555554;
	fma.rn.f64 	%fd161, %fd159, %fd146, %fd160;
	sub.f64 	%fd162, %fd143, %fd145;
	add.f64 	%fd163, %fd162, %fd162;
	neg.f64 	%fd164, %fd145;
	fma.rn.f64 	%fd165, %fd164, %fd143, %fd163;
	mul.f64 	%fd166, %fd142, %fd165;
	mul.f64 	%fd167, %fd146, %fd161;
	fma.rn.f64 	%fd168, %fd167, %fd145, %fd166;
	xor.b32  	%r143, %r287, -2147483648;
	mov.u32 	%r144, 1127219200;
	mov.b64 	%fd169, {%r143, %r144};
	mov.u32 	%r145, -2147483648;
	mov.b64 	%fd170, {%r145, %r144};
	sub.f64 	%fd171, %fd169, %fd170;
	mov.f64 	%fd172, 0d3FE62E42FEFA39EF;
	fma.rn.f64 	%fd173, %fd171, %fd172, %fd145;
	neg.f64 	%fd174, %fd171;
	fma.rn.f64 	%fd175, %fd174, %fd172, %fd173;
	sub.f64 	%fd176, %fd175, %fd145;
	sub.f64 	%fd177, %fd168, %fd176;
	mov.f64 	%fd178, 0d3C7ABC9E3B39803F;
	fma.rn.f64 	%fd179, %fd171, %fd178, %fd177;
	add.f64 	%fd295, %fd173, %fd179;
	bra.uni 	BB0_22;

BB0_18:
	mov.f64 	%fd134, 0d7FF0000000000000;
	fma.rn.f64 	%fd135, %fd293, %fd134, %fd134;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r136}, %fd293;
	}
	mov.b32 	 %f2, %r136;
	setp.eq.f32	%p20, %f2, 0f00000000;
	selp.f64	%fd295, 0dFFF0000000000000, %fd135, %p20;

BB0_22:
	mul.f64 	%fd180, %fd295, 0d3C7777D0FFDA0D24;
	fma.rn.f64 	%fd30, %fd295, %fd132, %fd180;
	mul.f64 	%fd182, %fd22, 0d3FE0000000000000;
	div.rn.f64 	%fd296, %fd182, %fd30;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r288}, %fd296;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%r289, %temp}, %fd296;
	}
	mov.u32 	%r290, -1023;
	setp.gt.s32	%p22, %r288, 1048575;
	@%p22 bra 	BB0_24;

	mul.f64 	%fd296, %fd296, 0d4350000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r288}, %fd296;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%r289, %temp}, %fd296;
	}
	mov.u32 	%r290, -1077;

BB0_24:
	add.s32 	%r148, %r288, -1;
	setp.lt.u32	%p23, %r148, 2146435071;
	@%p23 bra 	BB0_26;
	bra.uni 	BB0_25;

BB0_26:
	shr.u32 	%r150, %r288, 20;
	add.s32 	%r291, %r290, %r150;
	and.b32  	%r151, %r288, -2146435073;
	or.b32  	%r152, %r151, 1072693248;
	mov.b64 	%fd297, {%r289, %r152};
	setp.lt.s32	%p25, %r152, 1073127583;
	@%p25 bra 	BB0_28;

	{
	.reg .b32 %temp; 
	mov.b64 	{%r153, %temp}, %fd297;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r154}, %fd297;
	}
	add.s32 	%r155, %r154, -1048576;
	mov.b64 	%fd297, {%r153, %r155};
	add.s32 	%r291, %r291, 1;

BB0_28:
	add.f64 	%fd185, %fd297, 0d3FF0000000000000;
	rcp.approx.ftz.f64 	%fd186, %fd185;
	neg.f64 	%fd187, %fd185;
	mov.f64 	%fd188, 0d3FF0000000000000;
	fma.rn.f64 	%fd189, %fd187, %fd186, %fd188;
	fma.rn.f64 	%fd190, %fd189, %fd189, %fd189;
	fma.rn.f64 	%fd191, %fd190, %fd186, %fd186;
	add.f64 	%fd192, %fd297, 0dBFF0000000000000;
	mul.f64 	%fd193, %fd192, %fd191;
	fma.rn.f64 	%fd194, %fd192, %fd191, %fd193;
	mul.f64 	%fd195, %fd194, %fd194;
	mov.f64 	%fd196, 0d3ED0EE258B7A8B04;
	mov.f64 	%fd197, 0d3EB1380B3AE80F1E;
	fma.rn.f64 	%fd198, %fd197, %fd195, %fd196;
	mov.f64 	%fd199, 0d3EF3B2669F02676F;
	fma.rn.f64 	%fd200, %fd198, %fd195, %fd199;
	mov.f64 	%fd201, 0d3F1745CBA9AB0956;
	fma.rn.f64 	%fd202, %fd200, %fd195, %fd201;
	mov.f64 	%fd203, 0d3F3C71C72D1B5154;
	fma.rn.f64 	%fd204, %fd202, %fd195, %fd203;
	mov.f64 	%fd205, 0d3F624924923BE72D;
	fma.rn.f64 	%fd206, %fd204, %fd195, %fd205;
	mov.f64 	%fd207, 0d3F8999999999A3C4;
	fma.rn.f64 	%fd208, %fd206, %fd195, %fd207;
	mov.f64 	%fd209, 0d3FB5555555555554;
	fma.rn.f64 	%fd210, %fd208, %fd195, %fd209;
	sub.f64 	%fd211, %fd192, %fd194;
	add.f64 	%fd212, %fd211, %fd211;
	neg.f64 	%fd213, %fd194;
	fma.rn.f64 	%fd214, %fd213, %fd192, %fd212;
	mul.f64 	%fd215, %fd191, %fd214;
	mul.f64 	%fd216, %fd195, %fd210;
	fma.rn.f64 	%fd217, %fd216, %fd194, %fd215;
	xor.b32  	%r156, %r291, -2147483648;
	mov.u32 	%r157, 1127219200;
	mov.b64 	%fd218, {%r156, %r157};
	mov.u32 	%r158, -2147483648;
	mov.b64 	%fd219, {%r158, %r157};
	sub.f64 	%fd220, %fd218, %fd219;
	mov.f64 	%fd221, 0d3FE62E42FEFA39EF;
	fma.rn.f64 	%fd222, %fd220, %fd221, %fd194;
	neg.f64 	%fd223, %fd220;
	fma.rn.f64 	%fd224, %fd223, %fd221, %fd222;
	sub.f64 	%fd225, %fd224, %fd194;
	sub.f64 	%fd226, %fd217, %fd225;
	mov.f64 	%fd227, 0d3C7ABC9E3B39803F;
	fma.rn.f64 	%fd228, %fd220, %fd227, %fd226;
	add.f64 	%fd298, %fd222, %fd228;
	bra.uni 	BB0_29;

BB0_25:
	mov.f64 	%fd183, 0d7FF0000000000000;
	fma.rn.f64 	%fd184, %fd296, %fd183, %fd183;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r149}, %fd296;
	}
	mov.b32 	 %f3, %r149;
	setp.eq.f32	%p24, %f3, 0f00000000;
	selp.f64	%fd298, 0dFFF0000000000000, %fd184, %p24;

BB0_29:
	mul.f64 	%fd229, %fd298, 0d3C7777D0FFDA0D24;
	fma.rn.f64 	%fd231, %fd298, %fd132, %fd229;
	div.rn.f64 	%fd232, %fd231, %fd30;
	cvt.rn.f64.s32	%fd233, %r279;
	add.f64 	%fd234, %fd233, 0d3FF0000000000000;
	sub.f64 	%fd40, %fd234, %fd232;
	cvt.rzi.s32.f64	%r159, %fd40;
	add.s32 	%r160, %r90, -1;
	rem.s32 	%r161, %r159, %r160;
	mul.wide.s32 	%rd28, %r161, 4;
	add.s64 	%rd29, %rd2, %rd28;
	ld.global.u32 	%r35, [%rd29];
	add.f64 	%fd302, %fd40, 0d3FF0000000000000;
	cvt.rzi.s32.f64	%r162, %fd302;
	rem.s32 	%r163, %r162, %r160;
	mul.wide.s32 	%rd30, %r163, 4;
	add.s64 	%rd31, %rd2, %rd30;
	ld.global.u32 	%r36, [%rd31];
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r37}, %fd40;
	}
	and.b32  	%r164, %r37, 2147483647;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r165, %temp}, %fd40;
	}
	mov.f64 	%fd235, 0d3FF0000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r166}, %fd235;
	}
	and.b32  	%r167, %r166, 2147483647;
	mov.b64 	%fd299, {%r165, %r164};
	{
	.reg .b32 %temp; 
	mov.b64 	{%r168, %temp}, %fd235;
	}
	mov.b64 	%fd300, {%r168, %r167};
	setp.gt.u32	%p26, %r164, 2146435071;
	setp.gt.u32	%p27, %r167, 2146435071;
	or.pred  	%p28, %p26, %p27;
	@%p28 bra 	BB0_55;
	bra.uni 	BB0_30;

BB0_55:
	setp.gtu.f64	%p75, %fd299, 0d7FF0000000000000;
	setp.gtu.f64	%p76, %fd300, 0d7FF0000000000000;
	or.pred  	%p77, %p75, %p76;
	@%p77 bra 	BB0_57;

	setp.eq.f64	%p78, %fd299, 0d7FF0000000000000;
	selp.f64	%fd302, 0dFFF8000000000000, %fd40, %p78;
	bra.uni 	BB0_57;

BB0_30:
	setp.eq.f64	%p29, %fd300, 0d0000000000000000;
	mov.f64 	%fd302, 0dFFF8000000000000;
	@%p29 bra 	BB0_57;

	setp.ltu.f64	%p30, %fd299, %fd300;
	mov.f64 	%fd302, %fd40;
	@%p30 bra 	BB0_57;

	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r169}, %fd299;
	}
	shr.u32 	%r292, %r169, 20;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r170}, %fd300;
	}
	shr.u32 	%r293, %r170, 20;
	setp.ne.s32	%p31, %r292, 0;
	@%p31 bra 	BB0_34;

	mul.f64 	%fd299, %fd299, 0d4350000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r171}, %fd299;
	}
	shr.u32 	%r172, %r171, 20;
	add.s32 	%r292, %r172, -54;

BB0_34:
	setp.ne.s32	%p32, %r293, 0;
	@%p32 bra 	BB0_36;

	mul.f64 	%fd300, %fd300, 0d4350000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r173}, %fd300;
	}
	shr.u32 	%r174, %r173, 20;
	add.s32 	%r293, %r174, -54;

BB0_36:
	mov.b64 	 %rd33, %fd299;
	and.b64  	%rd34, %rd33, 4503599627370495;
	or.b64  	%rd10, %rd34, 4503599627370496;
	mov.b64 	 %rd35, %fd300;
	and.b64  	%rd36, %rd35, 4503599627370495;
	or.b64  	%rd4, %rd36, 4503599627370496;
	sub.s32 	%r52, %r292, %r293;
	not.b32 	%r175, %r292;
	add.s32 	%r176, %r293, %r175;
	mov.u32 	%r177, -1;
	max.s32 	%r178, %r176, %r177;
	add.s32 	%r179, %r292, 2;
	sub.s32 	%r180, %r179, %r293;
	add.s32 	%r45, %r180, %r178;
	and.b32  	%r46, %r45, 3;
	setp.eq.s32	%p33, %r46, 0;
	mov.u64 	%rd160, 0;
	@%p33 bra 	BB0_42;

	setp.eq.s32	%p34, %r46, 1;
	@%p34 bra 	BB0_41;

	setp.eq.s32	%p35, %r46, 2;
	@%p35 bra 	BB0_40;

	sub.s64 	%rd37, %rd10, %rd4;
	mov.b64 	 %fd237, %rd37;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r181}, %fd237;
	}
	setp.lt.s32	%p36, %r181, 0;
	selp.b64	%rd38, %rd10, %rd37, %p36;
	add.s64 	%rd10, %rd38, %rd38;
	add.s32 	%r52, %r52, -1;

BB0_40:
	sub.s64 	%rd39, %rd10, %rd4;
	mov.b64 	 %fd238, %rd39;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r182}, %fd238;
	}
	setp.lt.s32	%p37, %r182, 0;
	selp.b64	%rd40, %rd10, %rd39, %p37;
	add.s64 	%rd10, %rd40, %rd40;
	add.s32 	%r52, %r52, -1;

BB0_41:
	sub.s64 	%rd41, %rd10, %rd4;
	mov.b64 	 %fd239, %rd41;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r183}, %fd239;
	}
	setp.lt.s32	%p38, %r183, 0;
	selp.b64	%rd42, %rd10, %rd41, %p38;
	add.s64 	%rd10, %rd42, %rd42;
	add.s32 	%r52, %r52, -1;
	mov.u64 	%rd160, %rd10;

BB0_42:
	setp.lt.u32	%p39, %r45, 4;
	@%p39 bra 	BB0_52;

	mov.u32 	%r184, 2;
	sub.s32 	%r185, %r184, %r52;
	max.s32 	%r187, %r185, %r177;
	add.s32 	%r188, %r52, %r187;
	add.s32 	%r189, %r188, 1;
	shr.u32 	%r190, %r189, 2;
	add.s32 	%r53, %r190, 1;
	and.b32  	%r54, %r53, 3;
	setp.eq.s32	%p40, %r54, 0;
	mov.u64 	%rd160, 0;
	@%p40 bra 	BB0_49;

	setp.eq.s32	%p41, %r54, 1;
	@%p41 bra 	BB0_48;

	setp.eq.s32	%p42, %r54, 2;
	@%p42 bra 	BB0_47;

	sub.s64 	%rd44, %rd10, %rd4;
	mov.b64 	 %fd240, %rd44;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r191}, %fd240;
	}
	setp.lt.s32	%p43, %r191, 0;
	selp.b64	%rd45, %rd10, %rd44, %p43;
	add.s64 	%rd46, %rd45, %rd45;
	sub.s64 	%rd47, %rd46, %rd4;
	mov.b64 	 %fd241, %rd47;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r192}, %fd241;
	}
	setp.lt.s32	%p44, %r192, 0;
	selp.b64	%rd48, %rd46, %rd47, %p44;
	add.s64 	%rd49, %rd48, %rd48;
	sub.s64 	%rd50, %rd49, %rd4;
	mov.b64 	 %fd242, %rd50;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r193}, %fd242;
	}
	setp.lt.s32	%p45, %r193, 0;
	selp.b64	%rd51, %rd49, %rd50, %p45;
	add.s64 	%rd52, %rd51, %rd51;
	sub.s64 	%rd53, %rd52, %rd4;
	mov.b64 	 %fd243, %rd53;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r194}, %fd243;
	}
	setp.lt.s32	%p46, %r194, 0;
	selp.b64	%rd54, %rd52, %rd53, %p46;
	add.s64 	%rd10, %rd54, %rd54;
	add.s32 	%r52, %r52, -4;

BB0_47:
	sub.s64 	%rd55, %rd10, %rd4;
	mov.b64 	 %fd244, %rd55;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r195}, %fd244;
	}
	setp.lt.s32	%p47, %r195, 0;
	selp.b64	%rd56, %rd10, %rd55, %p47;
	add.s64 	%rd57, %rd56, %rd56;
	sub.s64 	%rd58, %rd57, %rd4;
	mov.b64 	 %fd245, %rd58;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r196}, %fd245;
	}
	setp.lt.s32	%p48, %r196, 0;
	selp.b64	%rd59, %rd57, %rd58, %p48;
	add.s64 	%rd60, %rd59, %rd59;
	sub.s64 	%rd61, %rd60, %rd4;
	mov.b64 	 %fd246, %rd61;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r197}, %fd246;
	}
	setp.lt.s32	%p49, %r197, 0;
	selp.b64	%rd62, %rd60, %rd61, %p49;
	add.s64 	%rd63, %rd62, %rd62;
	sub.s64 	%rd64, %rd63, %rd4;
	mov.b64 	 %fd247, %rd64;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r198}, %fd247;
	}
	setp.lt.s32	%p50, %r198, 0;
	selp.b64	%rd65, %rd63, %rd64, %p50;
	add.s64 	%rd10, %rd65, %rd65;
	add.s32 	%r52, %r52, -4;

BB0_48:
	sub.s64 	%rd66, %rd10, %rd4;
	mov.b64 	 %fd248, %rd66;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r199}, %fd248;
	}
	setp.lt.s32	%p51, %r199, 0;
	selp.b64	%rd67, %rd10, %rd66, %p51;
	add.s64 	%rd68, %rd67, %rd67;
	sub.s64 	%rd69, %rd68, %rd4;
	mov.b64 	 %fd249, %rd69;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r200}, %fd249;
	}
	setp.lt.s32	%p52, %r200, 0;
	selp.b64	%rd70, %rd68, %rd69, %p52;
	add.s64 	%rd71, %rd70, %rd70;
	sub.s64 	%rd72, %rd71, %rd4;
	mov.b64 	 %fd250, %rd72;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r201}, %fd250;
	}
	setp.lt.s32	%p53, %r201, 0;
	selp.b64	%rd73, %rd71, %rd72, %p53;
	add.s64 	%rd74, %rd73, %rd73;
	sub.s64 	%rd75, %rd74, %rd4;
	mov.b64 	 %fd251, %rd75;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r202}, %fd251;
	}
	setp.lt.s32	%p54, %r202, 0;
	selp.b64	%rd76, %rd74, %rd75, %p54;
	add.s64 	%rd10, %rd76, %rd76;
	add.s32 	%r52, %r52, -4;
	mov.u64 	%rd160, %rd10;

BB0_49:
	setp.lt.u32	%p55, %r53, 4;
	@%p55 bra 	BB0_52;

	mov.u64 	%rd160, %rd10;

BB0_51:
	sub.s64 	%rd77, %rd160, %rd4;
	mov.b64 	 %fd252, %rd77;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r203}, %fd252;
	}
	setp.lt.s32	%p56, %r203, 0;
	selp.b64	%rd78, %rd160, %rd77, %p56;
	add.s64 	%rd79, %rd78, %rd78;
	sub.s64 	%rd80, %rd79, %rd4;
	mov.b64 	 %fd253, %rd80;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r204}, %fd253;
	}
	setp.lt.s32	%p57, %r204, 0;
	selp.b64	%rd81, %rd79, %rd80, %p57;
	add.s64 	%rd82, %rd81, %rd81;
	sub.s64 	%rd83, %rd82, %rd4;
	mov.b64 	 %fd254, %rd83;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r205}, %fd254;
	}
	setp.lt.s32	%p58, %r205, 0;
	selp.b64	%rd84, %rd82, %rd83, %p58;
	add.s64 	%rd85, %rd84, %rd84;
	sub.s64 	%rd86, %rd85, %rd4;
	mov.b64 	 %fd255, %rd86;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r206}, %fd255;
	}
	setp.lt.s32	%p59, %r206, 0;
	selp.b64	%rd87, %rd85, %rd86, %p59;
	add.s64 	%rd88, %rd87, %rd87;
	sub.s64 	%rd89, %rd88, %rd4;
	mov.b64 	 %fd256, %rd89;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r207}, %fd256;
	}
	setp.lt.s32	%p60, %r207, 0;
	selp.b64	%rd90, %rd88, %rd89, %p60;
	add.s64 	%rd91, %rd90, %rd90;
	sub.s64 	%rd92, %rd91, %rd4;
	mov.b64 	 %fd257, %rd92;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r208}, %fd257;
	}
	setp.lt.s32	%p61, %r208, 0;
	selp.b64	%rd93, %rd91, %rd92, %p61;
	add.s64 	%rd94, %rd93, %rd93;
	sub.s64 	%rd95, %rd94, %rd4;
	mov.b64 	 %fd258, %rd95;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r209}, %fd258;
	}
	setp.lt.s32	%p62, %r209, 0;
	selp.b64	%rd96, %rd94, %rd95, %p62;
	add.s64 	%rd97, %rd96, %rd96;
	sub.s64 	%rd98, %rd97, %rd4;
	mov.b64 	 %fd259, %rd98;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r210}, %fd259;
	}
	setp.lt.s32	%p63, %r210, 0;
	selp.b64	%rd99, %rd97, %rd98, %p63;
	add.s64 	%rd100, %rd99, %rd99;
	sub.s64 	%rd101, %rd100, %rd4;
	mov.b64 	 %fd260, %rd101;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r211}, %fd260;
	}
	setp.lt.s32	%p64, %r211, 0;
	selp.b64	%rd102, %rd100, %rd101, %p64;
	add.s64 	%rd103, %rd102, %rd102;
	sub.s64 	%rd104, %rd103, %rd4;
	mov.b64 	 %fd261, %rd104;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r212}, %fd261;
	}
	setp.lt.s32	%p65, %r212, 0;
	selp.b64	%rd105, %rd103, %rd104, %p65;
	add.s64 	%rd106, %rd105, %rd105;
	sub.s64 	%rd107, %rd106, %rd4;
	mov.b64 	 %fd262, %rd107;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r213}, %fd262;
	}
	setp.lt.s32	%p66, %r213, 0;
	selp.b64	%rd108, %rd106, %rd107, %p66;
	add.s64 	%rd109, %rd108, %rd108;
	sub.s64 	%rd110, %rd109, %rd4;
	mov.b64 	 %fd263, %rd110;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r214}, %fd263;
	}
	setp.lt.s32	%p67, %r214, 0;
	selp.b64	%rd111, %rd109, %rd110, %p67;
	add.s64 	%rd112, %rd111, %rd111;
	sub.s64 	%rd113, %rd112, %rd4;
	mov.b64 	 %fd264, %rd113;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r215}, %fd264;
	}
	setp.lt.s32	%p68, %r215, 0;
	selp.b64	%rd114, %rd112, %rd113, %p68;
	add.s64 	%rd115, %rd114, %rd114;
	sub.s64 	%rd116, %rd115, %rd4;
	mov.b64 	 %fd265, %rd116;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r216}, %fd265;
	}
	setp.lt.s32	%p69, %r216, 0;
	selp.b64	%rd117, %rd115, %rd116, %p69;
	add.s64 	%rd118, %rd117, %rd117;
	sub.s64 	%rd119, %rd118, %rd4;
	mov.b64 	 %fd266, %rd119;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r217}, %fd266;
	}
	setp.lt.s32	%p70, %r217, 0;
	selp.b64	%rd120, %rd118, %rd119, %p70;
	add.s64 	%rd121, %rd120, %rd120;
	sub.s64 	%rd122, %rd121, %rd4;
	mov.b64 	 %fd267, %rd122;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r218}, %fd267;
	}
	setp.lt.s32	%p71, %r218, 0;
	selp.b64	%rd123, %rd121, %rd122, %p71;
	add.s64 	%rd160, %rd123, %rd123;
	add.s32 	%r62, %r52, -16;
	add.s32 	%r219, %r52, -15;
	setp.gt.s32	%p72, %r219, 0;
	mov.u32 	%r52, %r62;
	@%p72 bra 	BB0_51;

BB0_52:
	shr.u64 	%rd22, %rd160, 1;
	setp.eq.s64	%p73, %rd22, 0;
	mov.f64 	%fd301, 0d0000000000000000;
	@%p73 bra 	BB0_54;

	mov.b64 	 %fd269, %rd22;
	mul.f64 	%fd270, %fd269, 0d4350000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r220}, %fd270;
	}
	shr.u32 	%r221, %r220, 20;
	mov.u32 	%r222, 55;
	sub.s32 	%r223, %r222, %r221;
	sub.s32 	%r224, %r293, %r223;
	shl.b64 	%rd124, %rd22, %r223;
	setp.lt.s32	%p74, %r224, 1;
	mov.u32 	%r225, 1;
	sub.s32 	%r226, %r225, %r224;
	shr.u64 	%rd125, %rd124, %r226;
	add.s32 	%r227, %r224, 4095;
	cvt.u64.u32	%rd126, %r227;
	shl.b64 	%rd127, %rd126, 52;
	add.s64 	%rd128, %rd127, %rd124;
	selp.b64	%rd129, %rd125, %rd128, %p74;
	mov.b64 	 %fd301, %rd129;

BB0_54:
	and.b32  	%r228, %r37, -2147483648;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r229}, %fd301;
	}
	or.b32  	%r230, %r229, %r228;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r231, %temp}, %fd301;
	}
	mov.b64 	%fd302, {%r231, %r230};

BB0_57:
	mov.f64 	%fd285, 0d3FF0000000000000;
	bfe.u32 	%r232, %r35, 16, 8;
	bfe.u32 	%r233, %r35, 8, 8;
	bfe.u32 	%r234, %r36, 16, 8;
	bfe.u32 	%r235, %r36, 8, 8;
	cvt.rn.f64.s32	%fd271, %r232;
	sub.f64 	%fd273, %fd285, %fd302;
	mul.f64 	%fd274, %fd271, %fd273;
	cvt.rn.f64.s32	%fd275, %r234;
	fma.rn.f64 	%fd276, %fd275, %fd302, %fd274;
	cvt.rzi.s32.f64	%r236, %fd276;
	cvt.rn.f64.s32	%fd277, %r233;
	mul.f64 	%fd278, %fd277, %fd273;
	cvt.rn.f64.s32	%fd279, %r235;
	fma.rn.f64 	%fd280, %fd279, %fd302, %fd278;
	cvt.rzi.s32.f64	%r237, %fd280;
	and.b32  	%r238, %r35, 255;
	cvt.rn.f64.s32	%fd281, %r238;
	mul.f64 	%fd282, %fd281, %fd273;
	and.b32  	%r239, %r36, 255;
	cvt.rn.f64.s32	%fd283, %r239;
	fma.rn.f64 	%fd284, %fd283, %fd302, %fd282;
	cvt.rzi.s32.f64	%r240, %fd284;
	shl.b32 	%r241, %r236, 16;
	shl.b32 	%r242, %r237, 8;
	add.s32 	%r243, %r241, %r242;
	add.s32 	%r244, %r243, %r240;
	add.s32 	%r301, %r244, -16777216;

BB0_58:
	add.s32 	%r65, %r302, %r98;
	setp.ge.u32	%p79, %r302, %r65;
	@%p79 bra 	BB0_83;

	ld.param.u32 	%r277, [perturbation_param_8];
	ld.param.u32 	%r276, [perturbation_param_10];
	mul.lo.s32 	%r275, %r276, %r277;
	add.s32 	%r67, %r1, %r98;
	mul.lo.s32 	%r68, %r275, %r117;
	and.b32  	%r69, %r98, 3;
	add.s32 	%r70, %r1, 1;

BB0_60:
	setp.ge.u32	%p80, %r1, %r67;
	@%p80 bra 	BB0_82;

	mul.lo.s32 	%r73, %r302, %r117;
	setp.eq.s32	%p81, %r69, 0;
	mov.u32 	%r306, %r1;
	@%p81 bra 	BB0_72;

	setp.eq.s32	%p82, %r69, 1;
	mov.u32 	%r304, %r1;
	@%p82 bra 	BB0_69;

	setp.eq.s32	%p83, %r69, 2;
	mov.u32 	%r303, %r1;
	@%p83 bra 	BB0_66;

	mov.u32 	%r278, %tid.x;
	add.s32 	%r274, %r103, %r278;
	add.s32 	%r75, %r274, %r73;
	setp.ge.u32	%p84, %r75, %r68;
	mov.u32 	%r303, %r70;
	@%p84 bra 	BB0_66;

	cvta.to.global.u64 	%rd130, %rd23;
	mul.wide.u32 	%rd131, %r75, 4;
	add.s64 	%rd132, %rd130, %rd131;
	st.global.u32 	[%rd132], %r301;
	mov.u32 	%r303, %r70;

BB0_66:
	add.s32 	%r77, %r303, %r73;
	setp.ge.u32	%p85, %r77, %r68;
	@%p85 bra 	BB0_68;

	cvta.to.global.u64 	%rd133, %rd23;
	mul.wide.u32 	%rd134, %r77, 4;
	add.s64 	%rd135, %rd133, %rd134;
	st.global.u32 	[%rd135], %r301;

BB0_68:
	add.s32 	%r304, %r303, 1;

BB0_69:
	add.s32 	%r80, %r304, %r73;
	setp.ge.u32	%p86, %r80, %r68;
	@%p86 bra 	BB0_71;

	cvta.to.global.u64 	%rd136, %rd23;
	mul.wide.u32 	%rd137, %r80, 4;
	add.s64 	%rd138, %rd136, %rd137;
	st.global.u32 	[%rd138], %r301;

BB0_71:
	add.s32 	%r306, %r304, 1;

BB0_72:
	setp.lt.u32	%p87, %r98, 4;
	@%p87 bra 	BB0_82;

BB0_73:
	add.s32 	%r84, %r306, %r73;
	setp.ge.u32	%p88, %r84, %r68;
	@%p88 bra 	BB0_75;

	cvta.to.global.u64 	%rd139, %rd23;
	mul.wide.u32 	%rd140, %r84, 4;
	add.s64 	%rd141, %rd139, %rd140;
	st.global.u32 	[%rd141], %r301;

BB0_75:
	add.s32 	%r85, %r84, 1;
	setp.ge.u32	%p89, %r85, %r68;
	@%p89 bra 	BB0_77;

	cvta.to.global.u64 	%rd142, %rd23;
	mul.wide.u32 	%rd143, %r85, 4;
	add.s64 	%rd144, %rd142, %rd143;
	st.global.u32 	[%rd144], %r301;

BB0_77:
	add.s32 	%r86, %r84, 2;
	setp.ge.u32	%p90, %r86, %r68;
	@%p90 bra 	BB0_79;

	cvta.to.global.u64 	%rd145, %rd23;
	mul.wide.u32 	%rd146, %r86, 4;
	add.s64 	%rd147, %rd145, %rd146;
	st.global.u32 	[%rd147], %r301;

BB0_79:
	add.s32 	%r87, %r84, 3;
	setp.ge.u32	%p91, %r87, %r68;
	@%p91 bra 	BB0_81;

	cvta.to.global.u64 	%rd148, %rd23;
	mul.wide.u32 	%rd149, %r87, 4;
	add.s64 	%rd150, %rd148, %rd149;
	st.global.u32 	[%rd150], %r301;

BB0_81:
	add.s32 	%r306, %r306, 4;
	setp.lt.u32	%p92, %r306, %r67;
	@%p92 bra 	BB0_73;

BB0_82:
	add.s32 	%r302, %r302, 1;
	setp.lt.u32	%p93, %r302, %r65;
	@%p93 bra 	BB0_60;

BB0_83:
	ret;
}

	// .globl	traditional
.visible .entry traditional(
	.param .u64 traditional_param_0,
	.param .u64 traditional_param_1,
	.param .u32 traditional_param_2,
	.param .u32 traditional_param_3,
	.param .u32 traditional_param_4,
	.param .u32 traditional_param_5,
	.param .u32 traditional_param_6,
	.param .u32 traditional_param_7,
	.param .u32 traditional_param_8,
	.param .f64 traditional_param_9,
	.param .f64 traditional_param_10,
	.param .f64 traditional_param_11,
	.param .f64 traditional_param_12,
	.param .u32 traditional_param_13,
	.param .u32 traditional_param_14,
	.param .u32 traditional_param_15
)
{
	.reg .pred 	%p<99>;
	.reg .f32 	%f<4>;
	.reg .b32 	%r<310>;
	.reg .f64 	%fd<298>;
	.reg .b64 	%rd<148>;


	ld.param.u64 	%rd23, [traditional_param_0];
	ld.param.u64 	%rd24, [traditional_param_1];
	ld.param.u32 	%r88, [traditional_param_2];
	ld.param.u32 	%r89, [traditional_param_3];
	ld.param.u32 	%r90, [traditional_param_4];
	ld.param.u32 	%r91, [traditional_param_5];
	ld.param.u32 	%r92, [traditional_param_6];
	ld.param.u32 	%r93, [traditional_param_7];
	ld.param.u32 	%r94, [traditional_param_8];
	ld.param.f64 	%fd53, [traditional_param_9];
	ld.param.f64 	%fd54, [traditional_param_10];
	ld.param.f64 	%fd55, [traditional_param_11];
	ld.param.f64 	%fd56, [traditional_param_12];
	ld.param.u32 	%r95, [traditional_param_13];
	ld.param.u32 	%r96, [traditional_param_14];
	ld.param.u32 	%r97, [traditional_param_15];
	mul.lo.s32 	%r98, %r91, %r89;
	mov.u32 	%r99, %ntid.x;
	mov.u32 	%r100, %ctaid.x;
	mad.lo.s32 	%r101, %r99, %r100, %r98;
	mov.u32 	%r102, %tid.x;
	add.s32 	%r1, %r101, %r102;
	mov.u32 	%r103, %ntid.y;
	mov.u32 	%r104, %ctaid.y;
	mul.lo.s32 	%r105, %r92, %r90;
	mad.lo.s32 	%r106, %r103, %r104, %r105;
	mov.u32 	%r107, %tid.y;
	add.s32 	%r305, %r106, %r107;
	rem.u32 	%r108, %r1, %r96;
	setp.ne.s32	%p3, %r108, 0;
	@%p3 bra 	BB1_86;

	rem.u32 	%r109, %r305, %r96;
	setp.ne.s32	%p4, %r109, 0;
	@%p4 bra 	BB1_86;

	div.u32 	%r110, %r1, %r96;
	mov.pred 	%p98, 0;
	and.b32  	%r111, %r110, 1;
	setp.eq.b32	%p6, %r111, 1;
	@%p6 bra 	BB1_4;

	div.u32 	%r112, %r305, %r96;
	and.b32  	%r113, %r112, 1;
	setp.eq.b32	%p7, %r113, 1;
	not.pred 	%p98, %p7;

BB1_4:
	setp.ne.s32	%p8, %r96, %r97;
	and.pred  	%p9, %p98, %p8;
	@%p9 bra 	BB1_86;

	mul.lo.s32 	%r116, %r93, %r91;
	cvt.rn.f64.u32	%fd63, %r116;
	add.f64 	%fd64, %fd53, %fd53;
	cvt.rn.f64.u32	%fd65, %r1;
	mul.f64 	%fd66, %fd64, %fd65;
	div.rn.f64 	%fd67, %fd66, %fd63;
	sub.f64 	%fd68, %fd67, %fd53;
	add.f64 	%fd1, %fd68, %fd55;
	mul.lo.s32 	%r117, %r94, %r92;
	cvt.rn.f64.u32	%fd69, %r117;
	add.f64 	%fd70, %fd54, %fd54;
	cvt.rn.f64.u32	%fd71, %r305;
	mul.f64 	%fd72, %fd70, %fd71;
	div.rn.f64 	%fd73, %fd72, %fd69;
	sub.f64 	%fd74, %fd73, %fd54;
	add.f64 	%fd2, %fd74, %fd56;
	mov.u32 	%r282, 0;
	mov.f64 	%fd284, 0d0000000000000000;
	setp.lt.s32	%p10, %r95, 1;
	@%p10 bra 	BB1_10;

	mov.f64 	%fd280, %fd284;
	mov.f64 	%fd281, %fd284;
	mov.f64 	%fd282, %fd284;
	mov.f64 	%fd283, %fd284;

BB1_7:
	sub.f64 	%fd75, %fd281, %fd280;
	add.f64 	%fd8, %fd1, %fd75;
	add.f64 	%fd76, %fd283, %fd283;
	fma.rn.f64 	%fd9, %fd76, %fd282, %fd2;
	setp.eq.f64	%p11, %fd283, %fd8;
	setp.eq.f64	%p12, %fd282, %fd9;
	and.pred  	%p13, %p11, %p12;
	@%p13 bra 	BB1_8;

	mul.f64 	%fd281, %fd8, %fd8;
	mul.f64 	%fd280, %fd9, %fd9;
	add.f64 	%fd284, %fd281, %fd280;
	add.s32 	%r282, %r282, 1;
	setp.lt.s32	%p14, %r282, %r95;
	setp.le.f64	%p15, %fd284, 0d4010000000000000;
	and.pred  	%p16, %p15, %p14;
	mov.f64 	%fd282, %fd9;
	mov.f64 	%fd283, %fd8;
	@%p16 bra 	BB1_7;
	bra.uni 	BB1_10;

BB1_8:
	mov.u32 	%r282, %r95;

BB1_10:
	setp.eq.s32	%p17, %r282, %r95;
	mov.u32 	%r304, -16777216;
	@%p17 bra 	BB1_61;

	{
	.reg .b32 %temp; 
	mov.b64 	{%r284, %temp}, %fd284;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r283}, %fd284;
	}
	mov.u32 	%r285, -1023;
	setp.gt.s32	%p18, %r283, 1048575;
	@%p18 bra 	BB1_13;

	mul.f64 	%fd284, %fd284, 0d4350000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r283}, %fd284;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%r284, %temp}, %fd284;
	}
	mov.u32 	%r285, -1077;

BB1_13:
	add.s32 	%r121, %r283, -1;
	setp.lt.u32	%p19, %r121, 2146435071;
	@%p19 bra 	BB1_15;
	bra.uni 	BB1_14;

BB1_15:
	shr.u32 	%r123, %r283, 20;
	add.s32 	%r286, %r285, %r123;
	and.b32  	%r124, %r283, -2146435073;
	or.b32  	%r125, %r124, 1072693248;
	mov.b64 	%fd286, {%r284, %r125};
	setp.lt.s32	%p21, %r125, 1073127583;
	@%p21 bra 	BB1_17;

	{
	.reg .b32 %temp; 
	mov.b64 	{%r126, %temp}, %fd286;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r127}, %fd286;
	}
	add.s32 	%r128, %r127, -1048576;
	mov.b64 	%fd286, {%r126, %r128};
	add.s32 	%r286, %r286, 1;

BB1_17:
	add.f64 	%fd79, %fd286, 0d3FF0000000000000;
	rcp.approx.ftz.f64 	%fd80, %fd79;
	neg.f64 	%fd81, %fd79;
	mov.f64 	%fd82, 0d3FF0000000000000;
	fma.rn.f64 	%fd83, %fd81, %fd80, %fd82;
	fma.rn.f64 	%fd84, %fd83, %fd83, %fd83;
	fma.rn.f64 	%fd85, %fd84, %fd80, %fd80;
	add.f64 	%fd86, %fd286, 0dBFF0000000000000;
	mul.f64 	%fd87, %fd86, %fd85;
	fma.rn.f64 	%fd88, %fd86, %fd85, %fd87;
	mul.f64 	%fd89, %fd88, %fd88;
	mov.f64 	%fd90, 0d3ED0EE258B7A8B04;
	mov.f64 	%fd91, 0d3EB1380B3AE80F1E;
	fma.rn.f64 	%fd92, %fd91, %fd89, %fd90;
	mov.f64 	%fd93, 0d3EF3B2669F02676F;
	fma.rn.f64 	%fd94, %fd92, %fd89, %fd93;
	mov.f64 	%fd95, 0d3F1745CBA9AB0956;
	fma.rn.f64 	%fd96, %fd94, %fd89, %fd95;
	mov.f64 	%fd97, 0d3F3C71C72D1B5154;
	fma.rn.f64 	%fd98, %fd96, %fd89, %fd97;
	mov.f64 	%fd99, 0d3F624924923BE72D;
	fma.rn.f64 	%fd100, %fd98, %fd89, %fd99;
	mov.f64 	%fd101, 0d3F8999999999A3C4;
	fma.rn.f64 	%fd102, %fd100, %fd89, %fd101;
	mov.f64 	%fd103, 0d3FB5555555555554;
	fma.rn.f64 	%fd104, %fd102, %fd89, %fd103;
	sub.f64 	%fd105, %fd86, %fd88;
	add.f64 	%fd106, %fd105, %fd105;
	neg.f64 	%fd107, %fd88;
	fma.rn.f64 	%fd108, %fd107, %fd86, %fd106;
	mul.f64 	%fd109, %fd85, %fd108;
	mul.f64 	%fd110, %fd89, %fd104;
	fma.rn.f64 	%fd111, %fd110, %fd88, %fd109;
	xor.b32  	%r129, %r286, -2147483648;
	mov.u32 	%r130, 1127219200;
	mov.b64 	%fd112, {%r129, %r130};
	mov.u32 	%r131, -2147483648;
	mov.b64 	%fd113, {%r131, %r130};
	sub.f64 	%fd114, %fd112, %fd113;
	mov.f64 	%fd115, 0d3FE62E42FEFA39EF;
	fma.rn.f64 	%fd116, %fd114, %fd115, %fd88;
	neg.f64 	%fd117, %fd114;
	fma.rn.f64 	%fd118, %fd117, %fd115, %fd116;
	sub.f64 	%fd119, %fd118, %fd88;
	sub.f64 	%fd120, %fd111, %fd119;
	mov.f64 	%fd121, 0d3C7ABC9E3B39803F;
	fma.rn.f64 	%fd122, %fd114, %fd121, %fd120;
	add.f64 	%fd287, %fd116, %fd122;
	bra.uni 	BB1_18;

BB1_14:
	mov.f64 	%fd77, 0d7FF0000000000000;
	fma.rn.f64 	%fd78, %fd284, %fd77, %fd77;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r122}, %fd284;
	}
	mov.b32 	 %f1, %r122;
	setp.eq.f32	%p20, %f1, 0f00000000;
	selp.f64	%fd287, 0dFFF0000000000000, %fd78, %p20;

BB1_18:
	mul.f64 	%fd124, %fd287, 0d3C7777D0FFDA0D24;
	mov.f64 	%fd125, 0d3FF71547652B82FE;
	fma.rn.f64 	%fd22, %fd287, %fd125, %fd124;
	mov.f64 	%fd288, 0d4000000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r288, %temp}, %fd288;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r287}, %fd288;
	}
	mov.u32 	%r289, -1023;
	setp.gt.s32	%p22, %r287, 1048575;
	@%p22 bra 	BB1_20;

	mov.f64 	%fd288, 0d4360000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r287}, %fd288;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%r288, %temp}, %fd288;
	}
	mov.u32 	%r289, -1077;

BB1_20:
	add.s32 	%r134, %r287, -1;
	setp.lt.u32	%p23, %r134, 2146435071;
	@%p23 bra 	BB1_22;
	bra.uni 	BB1_21;

BB1_22:
	shr.u32 	%r136, %r287, 20;
	add.s32 	%r290, %r289, %r136;
	and.b32  	%r137, %r287, -2146435073;
	or.b32  	%r138, %r137, 1072693248;
	mov.b64 	%fd289, {%r288, %r138};
	setp.lt.s32	%p25, %r138, 1073127583;
	@%p25 bra 	BB1_24;

	{
	.reg .b32 %temp; 
	mov.b64 	{%r139, %temp}, %fd289;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r140}, %fd289;
	}
	add.s32 	%r141, %r140, -1048576;
	mov.b64 	%fd289, {%r139, %r141};
	add.s32 	%r290, %r290, 1;

BB1_24:
	add.f64 	%fd129, %fd289, 0d3FF0000000000000;
	rcp.approx.ftz.f64 	%fd130, %fd129;
	neg.f64 	%fd131, %fd129;
	mov.f64 	%fd132, 0d3FF0000000000000;
	fma.rn.f64 	%fd133, %fd131, %fd130, %fd132;
	fma.rn.f64 	%fd134, %fd133, %fd133, %fd133;
	fma.rn.f64 	%fd135, %fd134, %fd130, %fd130;
	add.f64 	%fd136, %fd289, 0dBFF0000000000000;
	mul.f64 	%fd137, %fd136, %fd135;
	fma.rn.f64 	%fd138, %fd136, %fd135, %fd137;
	mul.f64 	%fd139, %fd138, %fd138;
	mov.f64 	%fd140, 0d3ED0EE258B7A8B04;
	mov.f64 	%fd141, 0d3EB1380B3AE80F1E;
	fma.rn.f64 	%fd142, %fd141, %fd139, %fd140;
	mov.f64 	%fd143, 0d3EF3B2669F02676F;
	fma.rn.f64 	%fd144, %fd142, %fd139, %fd143;
	mov.f64 	%fd145, 0d3F1745CBA9AB0956;
	fma.rn.f64 	%fd146, %fd144, %fd139, %fd145;
	mov.f64 	%fd147, 0d3F3C71C72D1B5154;
	fma.rn.f64 	%fd148, %fd146, %fd139, %fd147;
	mov.f64 	%fd149, 0d3F624924923BE72D;
	fma.rn.f64 	%fd150, %fd148, %fd139, %fd149;
	mov.f64 	%fd151, 0d3F8999999999A3C4;
	fma.rn.f64 	%fd152, %fd150, %fd139, %fd151;
	mov.f64 	%fd153, 0d3FB5555555555554;
	fma.rn.f64 	%fd154, %fd152, %fd139, %fd153;
	sub.f64 	%fd155, %fd136, %fd138;
	add.f64 	%fd156, %fd155, %fd155;
	neg.f64 	%fd157, %fd138;
	fma.rn.f64 	%fd158, %fd157, %fd136, %fd156;
	mul.f64 	%fd159, %fd135, %fd158;
	mul.f64 	%fd160, %fd139, %fd154;
	fma.rn.f64 	%fd161, %fd160, %fd138, %fd159;
	xor.b32  	%r142, %r290, -2147483648;
	mov.u32 	%r143, 1127219200;
	mov.b64 	%fd162, {%r142, %r143};
	mov.u32 	%r144, -2147483648;
	mov.b64 	%fd163, {%r144, %r143};
	sub.f64 	%fd164, %fd162, %fd163;
	mov.f64 	%fd165, 0d3FE62E42FEFA39EF;
	fma.rn.f64 	%fd166, %fd164, %fd165, %fd138;
	neg.f64 	%fd167, %fd164;
	fma.rn.f64 	%fd168, %fd167, %fd165, %fd166;
	sub.f64 	%fd169, %fd168, %fd138;
	sub.f64 	%fd170, %fd161, %fd169;
	mov.f64 	%fd171, 0d3C7ABC9E3B39803F;
	fma.rn.f64 	%fd172, %fd164, %fd171, %fd170;
	add.f64 	%fd290, %fd166, %fd172;
	bra.uni 	BB1_25;

BB1_21:
	mov.f64 	%fd127, 0d7FF0000000000000;
	fma.rn.f64 	%fd128, %fd288, %fd127, %fd127;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r135}, %fd288;
	}
	mov.b32 	 %f2, %r135;
	setp.eq.f32	%p24, %f2, 0f00000000;
	selp.f64	%fd290, 0dFFF0000000000000, %fd128, %p24;

BB1_25:
	mul.f64 	%fd173, %fd290, 0d3C7777D0FFDA0D24;
	fma.rn.f64 	%fd30, %fd290, %fd125, %fd173;
	mul.f64 	%fd175, %fd22, 0d3FE0000000000000;
	div.rn.f64 	%fd291, %fd175, %fd30;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r291}, %fd291;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%r292, %temp}, %fd291;
	}
	mov.u32 	%r293, -1023;
	setp.gt.s32	%p26, %r291, 1048575;
	@%p26 bra 	BB1_27;

	mul.f64 	%fd291, %fd291, 0d4350000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r291}, %fd291;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%r292, %temp}, %fd291;
	}
	mov.u32 	%r293, -1077;

BB1_27:
	add.s32 	%r147, %r291, -1;
	setp.lt.u32	%p27, %r147, 2146435071;
	@%p27 bra 	BB1_29;
	bra.uni 	BB1_28;

BB1_29:
	shr.u32 	%r149, %r291, 20;
	add.s32 	%r294, %r293, %r149;
	and.b32  	%r150, %r291, -2146435073;
	or.b32  	%r151, %r150, 1072693248;
	mov.b64 	%fd292, {%r292, %r151};
	setp.lt.s32	%p29, %r151, 1073127583;
	@%p29 bra 	BB1_31;

	{
	.reg .b32 %temp; 
	mov.b64 	{%r152, %temp}, %fd292;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r153}, %fd292;
	}
	add.s32 	%r154, %r153, -1048576;
	mov.b64 	%fd292, {%r152, %r154};
	add.s32 	%r294, %r294, 1;

BB1_31:
	add.f64 	%fd178, %fd292, 0d3FF0000000000000;
	rcp.approx.ftz.f64 	%fd179, %fd178;
	neg.f64 	%fd180, %fd178;
	mov.f64 	%fd181, 0d3FF0000000000000;
	fma.rn.f64 	%fd182, %fd180, %fd179, %fd181;
	fma.rn.f64 	%fd183, %fd182, %fd182, %fd182;
	fma.rn.f64 	%fd184, %fd183, %fd179, %fd179;
	add.f64 	%fd185, %fd292, 0dBFF0000000000000;
	mul.f64 	%fd186, %fd185, %fd184;
	fma.rn.f64 	%fd187, %fd185, %fd184, %fd186;
	mul.f64 	%fd188, %fd187, %fd187;
	mov.f64 	%fd189, 0d3ED0EE258B7A8B04;
	mov.f64 	%fd190, 0d3EB1380B3AE80F1E;
	fma.rn.f64 	%fd191, %fd190, %fd188, %fd189;
	mov.f64 	%fd192, 0d3EF3B2669F02676F;
	fma.rn.f64 	%fd193, %fd191, %fd188, %fd192;
	mov.f64 	%fd194, 0d3F1745CBA9AB0956;
	fma.rn.f64 	%fd195, %fd193, %fd188, %fd194;
	mov.f64 	%fd196, 0d3F3C71C72D1B5154;
	fma.rn.f64 	%fd197, %fd195, %fd188, %fd196;
	mov.f64 	%fd198, 0d3F624924923BE72D;
	fma.rn.f64 	%fd199, %fd197, %fd188, %fd198;
	mov.f64 	%fd200, 0d3F8999999999A3C4;
	fma.rn.f64 	%fd201, %fd199, %fd188, %fd200;
	mov.f64 	%fd202, 0d3FB5555555555554;
	fma.rn.f64 	%fd203, %fd201, %fd188, %fd202;
	sub.f64 	%fd204, %fd185, %fd187;
	add.f64 	%fd205, %fd204, %fd204;
	neg.f64 	%fd206, %fd187;
	fma.rn.f64 	%fd207, %fd206, %fd185, %fd205;
	mul.f64 	%fd208, %fd184, %fd207;
	mul.f64 	%fd209, %fd188, %fd203;
	fma.rn.f64 	%fd210, %fd209, %fd187, %fd208;
	xor.b32  	%r155, %r294, -2147483648;
	mov.u32 	%r156, 1127219200;
	mov.b64 	%fd211, {%r155, %r156};
	mov.u32 	%r157, -2147483648;
	mov.b64 	%fd212, {%r157, %r156};
	sub.f64 	%fd213, %fd211, %fd212;
	mov.f64 	%fd214, 0d3FE62E42FEFA39EF;
	fma.rn.f64 	%fd215, %fd213, %fd214, %fd187;
	neg.f64 	%fd216, %fd213;
	fma.rn.f64 	%fd217, %fd216, %fd214, %fd215;
	sub.f64 	%fd218, %fd217, %fd187;
	sub.f64 	%fd219, %fd210, %fd218;
	mov.f64 	%fd220, 0d3C7ABC9E3B39803F;
	fma.rn.f64 	%fd221, %fd213, %fd220, %fd219;
	add.f64 	%fd293, %fd215, %fd221;
	bra.uni 	BB1_32;

BB1_28:
	mov.f64 	%fd176, 0d7FF0000000000000;
	fma.rn.f64 	%fd177, %fd291, %fd176, %fd176;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r148}, %fd291;
	}
	mov.b32 	 %f3, %r148;
	setp.eq.f32	%p28, %f3, 0f00000000;
	selp.f64	%fd293, 0dFFF0000000000000, %fd177, %p28;

BB1_32:
	mul.f64 	%fd222, %fd293, 0d3C7777D0FFDA0D24;
	fma.rn.f64 	%fd224, %fd293, %fd125, %fd222;
	div.rn.f64 	%fd225, %fd224, %fd30;
	cvt.rn.f64.s32	%fd226, %r282;
	add.f64 	%fd227, %fd226, 0d3FF0000000000000;
	sub.f64 	%fd40, %fd227, %fd225;
	cvt.rzi.s32.f64	%r158, %fd40;
	add.s32 	%r159, %r88, -1;
	rem.s32 	%r160, %r158, %r159;
	cvta.to.global.u64 	%rd25, %rd24;
	mul.wide.s32 	%rd26, %r160, 4;
	add.s64 	%rd27, %rd25, %rd26;
	ld.global.u32 	%r36, [%rd27];
	add.f64 	%fd297, %fd40, 0d3FF0000000000000;
	cvt.rzi.s32.f64	%r161, %fd297;
	rem.s32 	%r162, %r161, %r159;
	mul.wide.s32 	%rd28, %r162, 4;
	add.s64 	%rd29, %rd25, %rd28;
	ld.global.u32 	%r37, [%rd29];
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r38}, %fd40;
	}
	and.b32  	%r163, %r38, 2147483647;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r164, %temp}, %fd40;
	}
	mov.f64 	%fd228, 0d3FF0000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r165}, %fd228;
	}
	and.b32  	%r166, %r165, 2147483647;
	mov.b64 	%fd294, {%r164, %r163};
	{
	.reg .b32 %temp; 
	mov.b64 	{%r167, %temp}, %fd228;
	}
	mov.b64 	%fd295, {%r167, %r166};
	setp.gt.u32	%p30, %r163, 2146435071;
	setp.gt.u32	%p31, %r166, 2146435071;
	or.pred  	%p32, %p30, %p31;
	@%p32 bra 	BB1_58;
	bra.uni 	BB1_33;

BB1_58:
	setp.gtu.f64	%p79, %fd294, 0d7FF0000000000000;
	setp.gtu.f64	%p80, %fd295, 0d7FF0000000000000;
	or.pred  	%p81, %p79, %p80;
	@%p81 bra 	BB1_60;

	setp.eq.f64	%p82, %fd294, 0d7FF0000000000000;
	selp.f64	%fd297, 0dFFF8000000000000, %fd40, %p82;
	bra.uni 	BB1_60;

BB1_33:
	setp.eq.f64	%p33, %fd295, 0d0000000000000000;
	mov.f64 	%fd297, 0dFFF8000000000000;
	@%p33 bra 	BB1_60;

	setp.ltu.f64	%p34, %fd294, %fd295;
	mov.f64 	%fd297, %fd40;
	@%p34 bra 	BB1_60;

	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r168}, %fd294;
	}
	shr.u32 	%r295, %r168, 20;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r169}, %fd295;
	}
	shr.u32 	%r296, %r169, 20;
	setp.ne.s32	%p35, %r295, 0;
	@%p35 bra 	BB1_37;

	mul.f64 	%fd294, %fd294, 0d4350000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r170}, %fd294;
	}
	shr.u32 	%r171, %r170, 20;
	add.s32 	%r295, %r171, -54;

BB1_37:
	setp.ne.s32	%p36, %r296, 0;
	@%p36 bra 	BB1_39;

	mul.f64 	%fd295, %fd295, 0d4350000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r172}, %fd295;
	}
	shr.u32 	%r173, %r172, 20;
	add.s32 	%r296, %r173, -54;

BB1_39:
	mov.b64 	 %rd31, %fd294;
	and.b64  	%rd32, %rd31, 4503599627370495;
	or.b64  	%rd8, %rd32, 4503599627370496;
	mov.b64 	 %rd33, %fd295;
	and.b64  	%rd34, %rd33, 4503599627370495;
	or.b64  	%rd2, %rd34, 4503599627370496;
	sub.s32 	%r53, %r295, %r296;
	not.b32 	%r174, %r295;
	add.s32 	%r175, %r296, %r174;
	mov.u32 	%r176, -1;
	max.s32 	%r177, %r175, %r176;
	add.s32 	%r178, %r295, 2;
	sub.s32 	%r179, %r178, %r296;
	add.s32 	%r46, %r179, %r177;
	and.b32  	%r47, %r46, 3;
	setp.eq.s32	%p37, %r47, 0;
	mov.u64 	%rd147, 0;
	@%p37 bra 	BB1_45;

	setp.eq.s32	%p38, %r47, 1;
	@%p38 bra 	BB1_44;

	setp.eq.s32	%p39, %r47, 2;
	@%p39 bra 	BB1_43;

	sub.s64 	%rd35, %rd8, %rd2;
	mov.b64 	 %fd230, %rd35;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r180}, %fd230;
	}
	setp.lt.s32	%p40, %r180, 0;
	selp.b64	%rd36, %rd8, %rd35, %p40;
	add.s64 	%rd8, %rd36, %rd36;
	add.s32 	%r53, %r53, -1;

BB1_43:
	sub.s64 	%rd37, %rd8, %rd2;
	mov.b64 	 %fd231, %rd37;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r181}, %fd231;
	}
	setp.lt.s32	%p41, %r181, 0;
	selp.b64	%rd38, %rd8, %rd37, %p41;
	add.s64 	%rd8, %rd38, %rd38;
	add.s32 	%r53, %r53, -1;

BB1_44:
	sub.s64 	%rd39, %rd8, %rd2;
	mov.b64 	 %fd232, %rd39;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r182}, %fd232;
	}
	setp.lt.s32	%p42, %r182, 0;
	selp.b64	%rd40, %rd8, %rd39, %p42;
	add.s64 	%rd8, %rd40, %rd40;
	add.s32 	%r53, %r53, -1;
	mov.u64 	%rd147, %rd8;

BB1_45:
	setp.lt.u32	%p43, %r46, 4;
	@%p43 bra 	BB1_55;

	mov.u32 	%r183, 2;
	sub.s32 	%r184, %r183, %r53;
	max.s32 	%r186, %r184, %r176;
	add.s32 	%r187, %r53, %r186;
	add.s32 	%r188, %r187, 1;
	shr.u32 	%r189, %r188, 2;
	add.s32 	%r54, %r189, 1;
	and.b32  	%r55, %r54, 3;
	setp.eq.s32	%p44, %r55, 0;
	mov.u64 	%rd147, 0;
	@%p44 bra 	BB1_52;

	setp.eq.s32	%p45, %r55, 1;
	@%p45 bra 	BB1_51;

	setp.eq.s32	%p46, %r55, 2;
	@%p46 bra 	BB1_50;

	sub.s64 	%rd42, %rd8, %rd2;
	mov.b64 	 %fd233, %rd42;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r190}, %fd233;
	}
	setp.lt.s32	%p47, %r190, 0;
	selp.b64	%rd43, %rd8, %rd42, %p47;
	add.s64 	%rd44, %rd43, %rd43;
	sub.s64 	%rd45, %rd44, %rd2;
	mov.b64 	 %fd234, %rd45;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r191}, %fd234;
	}
	setp.lt.s32	%p48, %r191, 0;
	selp.b64	%rd46, %rd44, %rd45, %p48;
	add.s64 	%rd47, %rd46, %rd46;
	sub.s64 	%rd48, %rd47, %rd2;
	mov.b64 	 %fd235, %rd48;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r192}, %fd235;
	}
	setp.lt.s32	%p49, %r192, 0;
	selp.b64	%rd49, %rd47, %rd48, %p49;
	add.s64 	%rd50, %rd49, %rd49;
	sub.s64 	%rd51, %rd50, %rd2;
	mov.b64 	 %fd236, %rd51;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r193}, %fd236;
	}
	setp.lt.s32	%p50, %r193, 0;
	selp.b64	%rd52, %rd50, %rd51, %p50;
	add.s64 	%rd8, %rd52, %rd52;
	add.s32 	%r53, %r53, -4;

BB1_50:
	sub.s64 	%rd53, %rd8, %rd2;
	mov.b64 	 %fd237, %rd53;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r194}, %fd237;
	}
	setp.lt.s32	%p51, %r194, 0;
	selp.b64	%rd54, %rd8, %rd53, %p51;
	add.s64 	%rd55, %rd54, %rd54;
	sub.s64 	%rd56, %rd55, %rd2;
	mov.b64 	 %fd238, %rd56;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r195}, %fd238;
	}
	setp.lt.s32	%p52, %r195, 0;
	selp.b64	%rd57, %rd55, %rd56, %p52;
	add.s64 	%rd58, %rd57, %rd57;
	sub.s64 	%rd59, %rd58, %rd2;
	mov.b64 	 %fd239, %rd59;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r196}, %fd239;
	}
	setp.lt.s32	%p53, %r196, 0;
	selp.b64	%rd60, %rd58, %rd59, %p53;
	add.s64 	%rd61, %rd60, %rd60;
	sub.s64 	%rd62, %rd61, %rd2;
	mov.b64 	 %fd240, %rd62;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r197}, %fd240;
	}
	setp.lt.s32	%p54, %r197, 0;
	selp.b64	%rd63, %rd61, %rd62, %p54;
	add.s64 	%rd8, %rd63, %rd63;
	add.s32 	%r53, %r53, -4;

BB1_51:
	sub.s64 	%rd64, %rd8, %rd2;
	mov.b64 	 %fd241, %rd64;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r198}, %fd241;
	}
	setp.lt.s32	%p55, %r198, 0;
	selp.b64	%rd65, %rd8, %rd64, %p55;
	add.s64 	%rd66, %rd65, %rd65;
	sub.s64 	%rd67, %rd66, %rd2;
	mov.b64 	 %fd242, %rd67;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r199}, %fd242;
	}
	setp.lt.s32	%p56, %r199, 0;
	selp.b64	%rd68, %rd66, %rd67, %p56;
	add.s64 	%rd69, %rd68, %rd68;
	sub.s64 	%rd70, %rd69, %rd2;
	mov.b64 	 %fd243, %rd70;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r200}, %fd243;
	}
	setp.lt.s32	%p57, %r200, 0;
	selp.b64	%rd71, %rd69, %rd70, %p57;
	add.s64 	%rd72, %rd71, %rd71;
	sub.s64 	%rd73, %rd72, %rd2;
	mov.b64 	 %fd244, %rd73;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r201}, %fd244;
	}
	setp.lt.s32	%p58, %r201, 0;
	selp.b64	%rd74, %rd72, %rd73, %p58;
	add.s64 	%rd8, %rd74, %rd74;
	add.s32 	%r53, %r53, -4;
	mov.u64 	%rd147, %rd8;

BB1_52:
	setp.lt.u32	%p59, %r54, 4;
	@%p59 bra 	BB1_55;

	mov.u64 	%rd147, %rd8;

BB1_54:
	sub.s64 	%rd75, %rd147, %rd2;
	mov.b64 	 %fd245, %rd75;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r202}, %fd245;
	}
	setp.lt.s32	%p60, %r202, 0;
	selp.b64	%rd76, %rd147, %rd75, %p60;
	add.s64 	%rd77, %rd76, %rd76;
	sub.s64 	%rd78, %rd77, %rd2;
	mov.b64 	 %fd246, %rd78;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r203}, %fd246;
	}
	setp.lt.s32	%p61, %r203, 0;
	selp.b64	%rd79, %rd77, %rd78, %p61;
	add.s64 	%rd80, %rd79, %rd79;
	sub.s64 	%rd81, %rd80, %rd2;
	mov.b64 	 %fd247, %rd81;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r204}, %fd247;
	}
	setp.lt.s32	%p62, %r204, 0;
	selp.b64	%rd82, %rd80, %rd81, %p62;
	add.s64 	%rd83, %rd82, %rd82;
	sub.s64 	%rd84, %rd83, %rd2;
	mov.b64 	 %fd248, %rd84;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r205}, %fd248;
	}
	setp.lt.s32	%p63, %r205, 0;
	selp.b64	%rd85, %rd83, %rd84, %p63;
	add.s64 	%rd86, %rd85, %rd85;
	sub.s64 	%rd87, %rd86, %rd2;
	mov.b64 	 %fd249, %rd87;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r206}, %fd249;
	}
	setp.lt.s32	%p64, %r206, 0;
	selp.b64	%rd88, %rd86, %rd87, %p64;
	add.s64 	%rd89, %rd88, %rd88;
	sub.s64 	%rd90, %rd89, %rd2;
	mov.b64 	 %fd250, %rd90;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r207}, %fd250;
	}
	setp.lt.s32	%p65, %r207, 0;
	selp.b64	%rd91, %rd89, %rd90, %p65;
	add.s64 	%rd92, %rd91, %rd91;
	sub.s64 	%rd93, %rd92, %rd2;
	mov.b64 	 %fd251, %rd93;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r208}, %fd251;
	}
	setp.lt.s32	%p66, %r208, 0;
	selp.b64	%rd94, %rd92, %rd93, %p66;
	add.s64 	%rd95, %rd94, %rd94;
	sub.s64 	%rd96, %rd95, %rd2;
	mov.b64 	 %fd252, %rd96;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r209}, %fd252;
	}
	setp.lt.s32	%p67, %r209, 0;
	selp.b64	%rd97, %rd95, %rd96, %p67;
	add.s64 	%rd98, %rd97, %rd97;
	sub.s64 	%rd99, %rd98, %rd2;
	mov.b64 	 %fd253, %rd99;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r210}, %fd253;
	}
	setp.lt.s32	%p68, %r210, 0;
	selp.b64	%rd100, %rd98, %rd99, %p68;
	add.s64 	%rd101, %rd100, %rd100;
	sub.s64 	%rd102, %rd101, %rd2;
	mov.b64 	 %fd254, %rd102;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r211}, %fd254;
	}
	setp.lt.s32	%p69, %r211, 0;
	selp.b64	%rd103, %rd101, %rd102, %p69;
	add.s64 	%rd104, %rd103, %rd103;
	sub.s64 	%rd105, %rd104, %rd2;
	mov.b64 	 %fd255, %rd105;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r212}, %fd255;
	}
	setp.lt.s32	%p70, %r212, 0;
	selp.b64	%rd106, %rd104, %rd105, %p70;
	add.s64 	%rd107, %rd106, %rd106;
	sub.s64 	%rd108, %rd107, %rd2;
	mov.b64 	 %fd256, %rd108;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r213}, %fd256;
	}
	setp.lt.s32	%p71, %r213, 0;
	selp.b64	%rd109, %rd107, %rd108, %p71;
	add.s64 	%rd110, %rd109, %rd109;
	sub.s64 	%rd111, %rd110, %rd2;
	mov.b64 	 %fd257, %rd111;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r214}, %fd257;
	}
	setp.lt.s32	%p72, %r214, 0;
	selp.b64	%rd112, %rd110, %rd111, %p72;
	add.s64 	%rd113, %rd112, %rd112;
	sub.s64 	%rd114, %rd113, %rd2;
	mov.b64 	 %fd258, %rd114;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r215}, %fd258;
	}
	setp.lt.s32	%p73, %r215, 0;
	selp.b64	%rd115, %rd113, %rd114, %p73;
	add.s64 	%rd116, %rd115, %rd115;
	sub.s64 	%rd117, %rd116, %rd2;
	mov.b64 	 %fd259, %rd117;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r216}, %fd259;
	}
	setp.lt.s32	%p74, %r216, 0;
	selp.b64	%rd118, %rd116, %rd117, %p74;
	add.s64 	%rd119, %rd118, %rd118;
	sub.s64 	%rd120, %rd119, %rd2;
	mov.b64 	 %fd260, %rd120;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r217}, %fd260;
	}
	setp.lt.s32	%p75, %r217, 0;
	selp.b64	%rd121, %rd119, %rd120, %p75;
	add.s64 	%rd147, %rd121, %rd121;
	add.s32 	%r63, %r53, -16;
	add.s32 	%r218, %r53, -15;
	setp.gt.s32	%p76, %r218, 0;
	mov.u32 	%r53, %r63;
	@%p76 bra 	BB1_54;

BB1_55:
	shr.u64 	%rd20, %rd147, 1;
	setp.eq.s64	%p77, %rd20, 0;
	mov.f64 	%fd296, 0d0000000000000000;
	@%p77 bra 	BB1_57;

	mov.b64 	 %fd262, %rd20;
	mul.f64 	%fd263, %fd262, 0d4350000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r219}, %fd263;
	}
	shr.u32 	%r220, %r219, 20;
	mov.u32 	%r221, 55;
	sub.s32 	%r222, %r221, %r220;
	sub.s32 	%r223, %r296, %r222;
	shl.b64 	%rd122, %rd20, %r222;
	setp.lt.s32	%p78, %r223, 1;
	mov.u32 	%r224, 1;
	sub.s32 	%r225, %r224, %r223;
	shr.u64 	%rd123, %rd122, %r225;
	add.s32 	%r226, %r223, 4095;
	cvt.u64.u32	%rd124, %r226;
	shl.b64 	%rd125, %rd124, 52;
	add.s64 	%rd126, %rd125, %rd122;
	selp.b64	%rd127, %rd123, %rd126, %p78;
	mov.b64 	 %fd296, %rd127;

BB1_57:
	and.b32  	%r227, %r38, -2147483648;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r228}, %fd296;
	}
	or.b32  	%r229, %r228, %r227;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r230, %temp}, %fd296;
	}
	mov.b64 	%fd297, {%r230, %r229};

BB1_60:
	mov.f64 	%fd278, 0d3FF0000000000000;
	bfe.u32 	%r231, %r36, 16, 8;
	bfe.u32 	%r232, %r36, 8, 8;
	bfe.u32 	%r233, %r37, 16, 8;
	bfe.u32 	%r234, %r37, 8, 8;
	cvt.rn.f64.s32	%fd264, %r231;
	sub.f64 	%fd266, %fd278, %fd297;
	mul.f64 	%fd267, %fd264, %fd266;
	cvt.rn.f64.s32	%fd268, %r233;
	fma.rn.f64 	%fd269, %fd268, %fd297, %fd267;
	cvt.rzi.s32.f64	%r235, %fd269;
	cvt.rn.f64.s32	%fd270, %r232;
	mul.f64 	%fd271, %fd270, %fd266;
	cvt.rn.f64.s32	%fd272, %r234;
	fma.rn.f64 	%fd273, %fd272, %fd297, %fd271;
	cvt.rzi.s32.f64	%r236, %fd273;
	and.b32  	%r237, %r36, 255;
	cvt.rn.f64.s32	%fd274, %r237;
	mul.f64 	%fd275, %fd274, %fd266;
	and.b32  	%r238, %r37, 255;
	cvt.rn.f64.s32	%fd276, %r238;
	fma.rn.f64 	%fd277, %fd276, %fd297, %fd275;
	cvt.rzi.s32.f64	%r239, %fd277;
	shl.b32 	%r240, %r235, 16;
	shl.b32 	%r241, %r236, 8;
	add.s32 	%r242, %r240, %r241;
	add.s32 	%r243, %r242, %r239;
	add.s32 	%r304, %r243, -16777216;

BB1_61:
	add.s32 	%r66, %r305, %r96;
	setp.ge.u32	%p83, %r305, %r66;
	@%p83 bra 	BB1_86;

	ld.param.u32 	%r279, [traditional_param_6];
	ld.param.u32 	%r278, [traditional_param_8];
	mul.lo.s32 	%r277, %r278, %r279;
	add.s32 	%r68, %r1, %r96;
	mul.lo.s32 	%r69, %r277, %r116;
	and.b32  	%r70, %r96, 3;
	add.s32 	%r71, %r1, 1;

BB1_63:
	setp.ge.u32	%p84, %r1, %r68;
	@%p84 bra 	BB1_85;

	mul.lo.s32 	%r74, %r305, %r116;
	setp.eq.s32	%p85, %r70, 0;
	mov.u32 	%r309, %r1;
	@%p85 bra 	BB1_75;

	setp.eq.s32	%p86, %r70, 1;
	mov.u32 	%r307, %r1;
	@%p86 bra 	BB1_72;

	setp.eq.s32	%p87, %r70, 2;
	mov.u32 	%r306, %r1;
	@%p87 bra 	BB1_69;

	mov.u32 	%r280, %tid.x;
	add.s32 	%r273, %r101, %r280;
	add.s32 	%r76, %r273, %r74;
	setp.ge.u32	%p88, %r76, %r69;
	mov.u32 	%r306, %r71;
	@%p88 bra 	BB1_69;

	cvta.to.global.u64 	%rd128, %rd23;
	mul.wide.s32 	%rd129, %r76, 4;
	add.s64 	%rd130, %rd128, %rd129;
	st.global.u32 	[%rd130], %r304;
	mov.u32 	%r306, %r71;

BB1_69:
	add.s32 	%r78, %r306, %r74;
	setp.ge.u32	%p89, %r78, %r69;
	@%p89 bra 	BB1_71;

	cvta.to.global.u64 	%rd131, %rd23;
	mul.wide.s32 	%rd132, %r78, 4;
	add.s64 	%rd133, %rd131, %rd132;
	st.global.u32 	[%rd133], %r304;

BB1_71:
	add.s32 	%r307, %r306, 1;

BB1_72:
	add.s32 	%r81, %r307, %r74;
	setp.ge.u32	%p90, %r81, %r69;
	@%p90 bra 	BB1_74;

	cvta.to.global.u64 	%rd134, %rd23;
	mul.wide.s32 	%rd135, %r81, 4;
	add.s64 	%rd136, %rd134, %rd135;
	st.global.u32 	[%rd136], %r304;

BB1_74:
	add.s32 	%r309, %r307, 1;

BB1_75:
	cvta.to.global.u64 	%rd21, %rd23;
	setp.lt.u32	%p91, %r96, 4;
	@%p91 bra 	BB1_85;

BB1_76:
	add.s32 	%r85, %r309, %r74;
	mul.wide.s32 	%rd137, %r85, 4;
	add.s64 	%rd22, %rd21, %rd137;
	setp.ge.u32	%p92, %r85, %r69;
	@%p92 bra 	BB1_78;

	st.global.u32 	[%rd22], %r304;

BB1_78:
	add.s32 	%r274, %r85, 1;
	setp.ge.u32	%p93, %r274, %r69;
	@%p93 bra 	BB1_80;

	st.global.u32 	[%rd22+4], %r304;

BB1_80:
	add.s32 	%r275, %r85, 2;
	setp.ge.u32	%p94, %r275, %r69;
	@%p94 bra 	BB1_82;

	st.global.u32 	[%rd22+8], %r304;

BB1_82:
	add.s32 	%r276, %r85, 3;
	setp.ge.u32	%p95, %r276, %r69;
	@%p95 bra 	BB1_84;

	st.global.u32 	[%rd22+12], %r304;

BB1_84:
	add.s32 	%r309, %r309, 4;
	setp.lt.u32	%p96, %r309, %r68;
	@%p96 bra 	BB1_76;

BB1_85:
	add.s32 	%r305, %r305, 1;
	setp.lt.u32	%p97, %r305, %r66;
	@%p97 bra 	BB1_63;

BB1_86:
	ret;
}


